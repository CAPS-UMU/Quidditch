[0/2] Re-checking globbed directories...
[0/8] Performing build step for 'codegen'
[0/2] Re-checking globbed directories...
[1/5] Building CXX object iree-configuration/iree/compiler/plugins/Quidditch/src/Quidditch/Dialect/SnitchDMA/Transforms/CMakeFiles/Quidditch_Dialect_SnitchDMA_Transforms_Passes.objects.dir/LegalizeDMAOperations.cpp.o
[2/5] Linking CXX static library iree-configuration/iree/lib/libQuidditch_Dialect_SnitchDMA_Transforms_Passes.a
[3/5] Linking CXX shared library iree-configuration/iree/lib/libIREECompiler.so
[4/5] Linking CXX executable iree-configuration/iree/tools/iree-compile
[5/5] Linking CXX executable tools/quidditch-opt
[2/8] No install step for 'codegen'
[2/8] No test step for 'codegen'
[4/8] Completed 'codegen'
[4/8] Performing build step for 'runtime'
[0/2] Re-checking globbed directories...
[0/41] Updating iree-compile
[0/2] Re-checking globbed directories...
ninja: no work to do.
[2/41] Generating pumpkin/pumpkin_module.h, pumpkin/pumpkin.o, pumpkin/pumpkin.h, pumpkin/pumpkin_llvm.h
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %4 = dma.start_transfer from %1 : memref<4x4xf64> to %cast : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: RADDISH PROBLEM: type.getShape().front() = 4 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %4 = dma.start_transfer from %1 : memref<4x4xf64> to %cast : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %6 = dma.start_transfer from %2 : memref<4x4xf64> to %cast_3 : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: RADDISH PROBLEM: type.getShape().front() = 4 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %6 = dma.start_transfer from %2 : memref<4x4xf64> to %cast_3 : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %8 = dma.start_transfer from %3 : memref<4x4xf64> to %cast_8 : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: RADDISH PROBLEM: type.getShape().front() = 4 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %8 = dma.start_transfer from %3 : memref<4x4xf64> to %cast_8 : memref<4x4xf64, strided<[4, 1]>>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %10 = dma.start_transfer from %reinterpret_cast_7 : memref<4x4xf64> to %3 : memref<4x4xf64>
  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: warning: RADDISH PROBLEM: type.getShape().front() = 4 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul 
            ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:9:5: note: called from
    func.func @matmulTiny(%lhs: tensor<4x4xf64>, %rhs: tensor<4x4xf64>, %acc: tensor<4x4xf64>) -> tensor<4x4xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/calabaza/pumpkin.mlir:10:13: note: see current operation: %10 = dma.start_transfer from %reinterpret_cast_7 : memref<4x4xf64> to %3 : memref<4x4xf64>
  %result = linalg.matmul 
            ^
[3/41] Building C object samples/calabaza/CMakeFiles/pumpkin.dir/pumpkin/pumpkin_module.c.obj
[4/41] Building C object samples/calabaza/CMakeFiles/calabaza.dir/main.c.obj
[5/41] Linking C static library samples/calabaza/libpumpkin.a
[6/41] Generating simple_add/simple_add_module.h, simple_add/simple_add.o, simple_add/simple_add.h, simple_add/simple_add_llvm.h
[7/41] Building C object samples/vec_multiply/CMakeFiles/simple_add.dir/simple_add/simple_add_module.c.obj
[8/41] Building C object samples/vec_multiply/CMakeFiles/vec_multiply.dir/main.c.obj
[9/41] Linking C static library samples/vec_multiply/libsimple_add.a
[10/41] Generating nsnet2_llvm/nsnet2_llvm_module.h, nsnet2_llvm/nsnet2_llvm.h, nsnet2_llvm/nsnet2_llvm.o
[11/41] Building C object samples/nsnet2/CMakeFiles/NsNet2LLVM.dir/NsNet2LLVM.c.obj
[12/41] Generating grapeFruit_llvm/grapeFruit_llvm_module.h, grapeFruit_llvm/grapeFruit_llvm.h, grapeFruit_llvm/grapeFruit_llvm.o
[13/41] Building C object samples/grapeFruit/CMakeFiles/GrapeFruitLLVM.dir/GrapeFruitLLVM.c.obj
[14/41] Generating pamplemousse/pamplemousse_module.h, pamplemousse/pamplemousse.o, pamplemousse/pamplemousse.h, pamplemousse/pamplemousse_llvm.h
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %4 = dma.start_transfer from %1 : memref<3x3xf64> to %cast : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: RADDISH PROBLEM: type.getShape().front() = 3 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %4 = dma.start_transfer from %1 : memref<3x3xf64> to %cast : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %6 = dma.start_transfer from %2 : memref<3x3xf64> to %cast_3 : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: RADDISH PROBLEM: type.getShape().front() = 3 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %6 = dma.start_transfer from %2 : memref<3x3xf64> to %cast_3 : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %8 = dma.start_transfer from %3 : memref<3x3xf64> to %cast_8 : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: RADDISH PROBLEM: type.getShape().front() = 3 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %8 = dma.start_transfer from %3 : memref<3x3xf64> to %cast_8 : memref<3x3xf64, strided<[3, 1]>>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %10 = dma.start_transfer from %reinterpret_cast_7 : memref<3x3xf64> to %3 : memref<3x3xf64>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: warning: RADDISH PROBLEM: type.getShape().front() = 3 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:2:3: note: called from
  func.func @matmulTiny(%lhs: tensor<3x3xf64>, %rhs: tensor<3x3xf64>, %acc: tensor<3x3xf64>) -> tensor<3x3xf64> {
  ^
/home/hoppip/Quidditch/runtime/samples/pomelo/pamplemousse.mlir:3:13: note: see current operation: %10 = dma.start_transfer from %reinterpret_cast_7 : memref<3x3xf64> to %3 : memref<3x3xf64>
  %result = linalg.matmul // changing linalg.add to linalg.matmul, causes a RESOURCE_EXHAUSTED error
            ^
[15/41] Building C object samples/pomelo/CMakeFiles/pomelo.dir/main.c.obj
[16/41] Building C object samples/pomelo/CMakeFiles/pamplemousse.dir/pamplemousse/pamplemousse_module.c.obj
[17/41] Linking C static library samples/pomelo/libpamplemousse.a
[18/41] Building C object samples/nsnet2/CMakeFiles/nsnet2_llvm.dir/nsnet2_llvm/nsnet2_llvm_module.c.obj
[19/41] Building C object samples/grapeFruit/CMakeFiles/grapeFruit_llvm.dir/grapeFruit_llvm/grapeFruit_llvm_module.c.obj
[20/41] Linking C static library samples/nsnet2/libnsnet2_llvm.a
[21/41] Linking C static library samples/grapeFruit/libgrapeFruit_llvm.a
[22/41] Generating big_matvec/big_matvec_module.h, big_matvec/big_matvec.o, big_matvec/big_matvec.h, big_matvec/big_matvec_llvm.h
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:4:14: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:2:5: note: called from
    func.func @test32(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:4:14: note: see current operation: %9 = dma.start_transfer from %subview_15 : memref<1x80xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x80xf64, strided<[80, 1]>>
      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:13:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:2:5: note: called from
    func.func @test32(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:13:15: note: see current operation: %6 = dma.start_transfer from %3 : memref<1x320xf64> to %cast_11 : memref<1x320xf64, strided<[320, 1]>>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:13:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:2:5: note: called from
    func.func @test32(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:13:15: note: see current operation: %9 = dma.start_transfer from %reinterpret_cast_10 : memref<1x320xf64> to %3 : memref<1x320xf64>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:29:14: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:27:5: note: called from
    func.func @test40(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:29:14: note: see current operation: %9 = dma.start_transfer from %subview_15 : memref<1x80xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x80xf64, strided<[80, 1]>>
      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:38:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:27:5: note: called from
    func.func @test40(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:38:15: note: see current operation: %6 = dma.start_transfer from %3 : memref<1x320xf64> to %cast_11 : memref<1x320xf64, strided<[320, 1]>>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:38:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:27:5: note: called from
    func.func @test40(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:38:15: note: see current operation: %9 = dma.start_transfer from %reinterpret_cast_10 : memref<1x320xf64> to %3 : memref<1x320xf64>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:54:14: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:52:5: note: called from
    func.func @test64(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:54:14: note: see current operation: %9 = dma.start_transfer from %subview_15 : memref<1x80xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x80xf64, strided<[80, 1]>>
      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:63:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:52:5: note: called from
    func.func @test64(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:63:15: note: see current operation: %6 = dma.start_transfer from %3 : memref<1x320xf64> to %cast_11 : memref<1x320xf64, strided<[320, 1]>>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:63:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:52:5: note: called from
    func.func @test64(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:63:15: note: see current operation: %9 = dma.start_transfer from %reinterpret_cast_10 : memref<1x320xf64> to %3 : memref<1x320xf64>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:79:14: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:77:5: note: called from
    func.func @test32_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:79:14: note: see current operation: %9 = dma.start_transfer from %subview_15 : memref<1x100xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:88:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:77:5: note: called from
    func.func @test32_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:88:15: note: see current operation: %6 = dma.start_transfer from %3 : memref<1x320xf64> to %cast_11 : memref<1x320xf64, strided<[320, 1]>>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:88:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:77:5: note: called from
    func.func @test32_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:88:15: note: see current operation: %9 = dma.start_transfer from %reinterpret_cast_10 : memref<1x320xf64> to %3 : memref<1x320xf64>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:104:14: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:102:5: note: called from
    func.func @test40_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:104:14: note: see current operation: %9 = dma.start_transfer from %subview_15 : memref<1x100xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
      %out = linalg.matmul_transpose_b {
             ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:113:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:102:5: note: called from
    func.func @test40_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:113:15: note: see current operation: %6 = dma.start_transfer from %3 : memref<1x320xf64> to %cast_11 : memref<1x320xf64, strided<[320, 1]>>
      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:113:15: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

      %out2 = linalg.generic {
              ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:102:5: note: called from
    func.func @test40_100(%arg0: tensor<1x400xf64>, %arg1: tensor<320x400xf64>) -> tensor<1x320xf64> {
    ^
/home/hoppip/Quidditch/runtime/samples/big_matvec/big_matvec.mlir:113:15: note: see current operation: %9 = dma.start_transfer from %reinterpret_cast_10 : memref<1x320xf64> to %3 : memref<1x320xf64>
      %out2 = linalg.generic {
              ^
[23/41] Building C object samples/big_matvec/CMakeFiles/big_matvec.dir/big_matvec/big_matvec_module.c.obj
[24/41] Building C object samples/big_matvec/CMakeFiles/big_matvec_sample.dir/main.c.obj
[25/41] Linking C static library samples/big_matvec/libbig_matvec.a
[26/41] Linking C executable samples/vec_multiply/vec_multiply
[27/41] Linking C executable samples/calabaza/calabaza
[28/41] Linking C executable samples/pomelo/pomelo
[29/41] Linking C executable samples/grapeFruit/GrapeFruitLLVM
[30/41] Linking C executable samples/nsnet2/NsNet2LLVM
[31/41] Linking C executable samples/big_matvec/big_matvec_sample
[32/41] Generating grapeFruit/grapeFruit_module.h, grapeFruit/grapeFruit.o, grapeFruit/grapeFruit.h, grapeFruit/grapeFruit_llvm.h, grapeFruit/grapeFruit_llvm.o
FAILED: samples/grapeFruit/grapeFruit/grapeFruit_module.h samples/grapeFruit/grapeFruit/grapeFruit.o samples/grapeFruit/grapeFruit/grapeFruit.h samples/grapeFruit/grapeFruit/grapeFruit_llvm.h samples/grapeFruit/grapeFruit/grapeFruit_llvm.o /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit_module.h /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit.o /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit.h /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit_llvm.h /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit_llvm.o 
cd /home/hoppip/Quidditch/build/runtime/samples/grapeFruit && /home/hoppip/Quidditch/build/codegen/iree-configuration/iree/tools/iree-compile --iree-quidditch-zigzag-tiling-scheme=/home/hoppip/Quidditch/zigzag_tiling/grapeFruit/snitch-cluster-only-floats-no-ssrs-dispatch_1_matmul_transpose_b_1x1200x400_f64/grapeFruit-tiling-scheme.json --iree-vm-bytecode-module-strip-source-map=true --iree-vm-emit-polyglot-zip=false --iree-input-type=auto --iree-input-demote-f64-to-f32=0 --iree-hal-target-backends=quidditch --iree-quidditch-static-library-output-path=/home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit.o --iree-quidditch-xdsl-opt-path=/home/hoppip/Quidditch/venv/bin/xdsl-opt --iree-quidditch-toolchain-root=/home/hoppip/Quidditch/toolchain --iree-hal-target-backends=llvm-cpu --iree-llvmcpu-debug-symbols=true --iree-llvmcpu-target-triple=riscv32-unknown-elf --iree-llvmcpu-target-cpu=generic-rv32 --iree-llvmcpu-target-cpu-features=+m,+f,+d,+zfh --iree-llvmcpu-target-abi=ilp32d --iree-llvmcpu-target-float-abi=hard --iree-llvmcpu-link-embedded=false --iree-llvmcpu-link-static --iree-llvmcpu-number-of-threads=8 --iree-llvmcpu-static-library-output-path=/home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit_llvm.o --output-format=vm-c --iree-vm-target-index-bits=32 /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit.mlirbc -o /home/hoppip/Quidditch/build/runtime/samples/grapeFruit/grapeFruit/grapeFruit_module.h
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: Failed to translate kernel with xDSL
/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
quidditch_snitch.memref.microkernel(<<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>) : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>> {
^bb0(%arg0: memref<50xf64, strided<[1], offset: ?>>, %arg1: memref<50xf64, strided<[1], offset: ?>>, %arg2: memref<50xf64, strided<[1], offset: ?>>, %arg3: memref<50xf64, strided<[1], offset: ?>>, %arg4: memref<50xf64, strided<[1], offset: ?>>, %arg5: memref<50xf64, strided<[1], offset: ?>>, %arg6: memref<50xf64, strided<[1], offset: ?>>, %arg7: memref<50xf64, strided<[1], offset: ?>>):
  %cst = arith.constant 1.000000e+00 : f64
  linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6 : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) outs(%arg7 : memref<50xf64, strided<[1], offset: ?>>) {
  ^bb0(%in: f64, %in_0: f64, %in_1: f64, %in_2: f64, %in_3: f64, %in_4: f64, %in_5: f64, %out: f64):
    %0 = arith.addf %in_4, %in_5 : f64
    %1 = arith.addf %in_2, %in_3 : f64
    %2 = arith.negf %1 : f64
    %3 = math.exp %2 : f64
    %4 = arith.addf %3, %cst : f64
    %5 = arith.divf %cst, %4 : f64
    %6 = arith.mulf %in_1, %5 : f64
    %7 = arith.addf %in_0, %6 : f64
    %8 = math.tanh %7 : f64
    %9 = arith.negf %0 : f64
    %10 = math.exp %9 : f64
    %11 = arith.addf %10, %cst : f64
    %12 = arith.divf %cst, %11 : f64
    %13 = arith.subf %in, %8 : f64
    %14 = arith.mulf %13, %12 : f64
    %15 = arith.addf %14, %8 : f64
    linalg.yield %15 : f64
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: stderr:
Traceback (most recent call last):
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 534, in parse_chunk
    return self.available_frontends[file_extension](chunk)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 520, in parse_mlir
    ).parse_module(not self.args.no_implicit_module)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 127, in parse_module
    if (parsed_op := self.parse_optional_operation()) is not None:
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/func.py", line 138, in parse
    ) = parse_func_op_like(
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/utils.py", line 239, in parse_func_op_like
    region = parser.parse_optional_region(entry_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 539, in parse_optional_region
    self._parse_block_body(entry_block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/linalg.py", line 354, in parse
    body = parser.parse_region()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 594, in parse_region
    region = self.parse_optional_region(arguments)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 558, in parse_optional_region
    block = self._parse_block()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 247, in _parse_block
    self._parse_block_body(block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/ir/core.py", line 869, in parse
    parser.raise_error(f"Operation {cls.name} does not have a custom format.")
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/base_parser.py", line 107, in raise_error
    raise ParseError(at_position, msg)
xdsl.utils.exceptions.ParseError: stdin:8:18
    %3 = math.exp %2 : f64
                  ^^
                  Operation math.exp does not have a custom format.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hoppip/Quidditch/venv/bin/xdsl-opt", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/xdsl_opt.py", line 5, in main
    xDSLOptMain().run()
  File "/home/hoppip/Quidditch/xdsl/xdsl/xdsl_opt_main.py", line 71, in run
    module = self.parse_chunk(chunk, file_extension, offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 541, in parse_chunk
    raise Exception("Failed to parse:\n" + e.with_context()) from e
Exception: Failed to parse:
stdin:8:18
    %3 = math.exp %2 : f64
                  ^^
                  Operation math.exp does not have a custom format.


<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: 
RADDISH: (convertToRISCV) convert to RISCV assembly failed

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
module {
  func.func @main$async_dispatch_3_elementwise_400_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_3_elementwise_400_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c22400 = arith.constant 22400 : index
    %c19200 = arith.constant 19200 : index
    %c16000 = arith.constant 16000 : index
    %c12800 = arith.constant 12800 : index
    %c9600 = arith.constant 9600 : index
    %c6400 = arith.constant 6400 : index
    %c3200 = arith.constant 3200 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.constant.load[0] : i32
    %2 = hal.interface.constant.load[1] : i32
    %3 = hal.interface.constant.load[2] : i32
    %4 = hal.interface.constant.load[3] : i32
    %5 = hal.interface.constant.load[4] : i32
    %6 = hal.interface.constant.load[5] : i32
    %7 = hal.interface.constant.load[6] : i32
    %8 = hal.interface.constant.load[7] : i32
    %9 = hal.interface.constant.load[8] : i32
    %10 = arith.extui %1 : i32 to i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.ori %10, %12 : i64
    %14 = arith.index_castui %13 {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : i64 to index
    %15 = arith.index_castui %3 : i32 to index
    %16 = arith.index_castui %4 : i32 to index
    %17 = arith.index_castui %5 : i32 to index
    %18 = arith.index_castui %6 : i32 to index
    %19 = arith.index_castui %7 : i32 to index
    %20 = arith.index_castui %8 : i32 to index
    %21 = arith.index_castui %9 : i32 to index
    %22 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%14) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %22, 64 : memref<400xf64, strided<[1], offset: ?>>
    %23 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%15) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %23, 1 : memref<400xf64, strided<[1], offset: ?>>
    %24 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%16) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %24, 1 : memref<400xf64, strided<[1], offset: ?>>
    %25 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%17) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %25, 1 : memref<400xf64, strided<[1], offset: ?>>
    %26 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%18) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %26, 1 : memref<400xf64, strided<[1], offset: ?>>
    %27 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%19) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %27, 1 : memref<400xf64, strided<[1], offset: ?>>
    %28 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%20) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %28, 1 : memref<400xf64, strided<[1], offset: ?>>
    %29 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%21) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %29, 1 : memref<400xf64, strided<[1], offset: ?>>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c3200][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_1 = memref.view %0[%c6400][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_2 = memref.view %0[%c9600][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_3 = memref.view %0[%c12800][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_4 = memref.view %0[%c16000][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_5 = memref.view %0[%c19200][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c22400][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %30 = quidditch_snitch.compute_core_index
    %31 = affine.apply affine_map<()[s0] -> (s0 * 50)>()[%30]
    %subview = memref.subview %view[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_7 = memref.subview %view_0[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_8 = memref.subview %view_1[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_9 = memref.subview %view_2[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_10 = memref.subview %view_3[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_11 = memref.subview %view_4[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_12 = memref.subview %view_5[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_13 = memref.subview %view_6[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    quidditch_snitch.memref.microkernel(%subview, %subview_7, %subview_8, %subview_9, %subview_10, %subview_11, %subview_12, %subview_13) : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>> {
    ^bb0(%arg0: memref<50xf64, strided<[1], offset: ?>>, %arg1: memref<50xf64, strided<[1], offset: ?>>, %arg2: memref<50xf64, strided<[1], offset: ?>>, %arg3: memref<50xf64, strided<[1], offset: ?>>, %arg4: memref<50xf64, strided<[1], offset: ?>>, %arg5: memref<50xf64, strided<[1], offset: ?>>, %arg6: memref<50xf64, strided<[1], offset: ?>>, %arg7: memref<50xf64, strided<[1], offset: ?>>):
      %cst = arith.constant 1.000000e+00 : f64
      linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6 : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) outs(%arg7 : memref<50xf64, strided<[1], offset: ?>>) {
      ^bb0(%in: f64, %in_14: f64, %in_15: f64, %in_16: f64, %in_17: f64, %in_18: f64, %in_19: f64, %out: f64):
        %32 = arith.addf %in_18, %in_19 : f64
        %33 = arith.addf %in_16, %in_17 : f64
        %34 = arith.negf %33 : f64
        %35 = math.exp %34 : f64
        %36 = arith.addf %35, %cst : f64
        %37 = arith.divf %cst, %36 : f64
        %38 = arith.mulf %in_15, %37 : f64
        %39 = arith.addf %in_14, %38 : f64
        %40 = math.tanh %39 : f64
        %41 = arith.negf %32 : f64
        %42 = math.exp %41 : f64
        %43 = arith.addf %42, %cst : f64
        %44 = arith.divf %cst, %43 : f64
        %45 = arith.subf %in, %40 : f64
        %46 = arith.mulf %45, %44 : f64
        %47 = arith.addf %46, %40 : f64
        linalg.yield %47 : f64
      }
    }
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_3_elementwise_400_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c22400 = arith.constant 22400 : index
    %c19200 = arith.constant 19200 : index
    %c16000 = arith.constant 16000 : index
    %c12800 = arith.constant 12800 : index
    %c9600 = arith.constant 9600 : index
    %c6400 = arith.constant 6400 : index
    %c3200 = arith.constant 3200 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.constant.load[0] : i32
    %2 = hal.interface.constant.load[1] : i32
    %3 = hal.interface.constant.load[2] : i32
    %4 = hal.interface.constant.load[3] : i32
    %5 = hal.interface.constant.load[4] : i32
    %6 = hal.interface.constant.load[5] : i32
    %7 = hal.interface.constant.load[6] : i32
    %8 = hal.interface.constant.load[7] : i32
    %9 = hal.interface.constant.load[8] : i32
    %10 = arith.extui %1 : i32 to i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.ori %10, %12 : i64
    %14 = arith.index_castui %13 {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : i64 to index
    %15 = arith.index_castui %3 : i32 to index
    %16 = arith.index_castui %4 : i32 to index
    %17 = arith.index_castui %5 : i32 to index
    %18 = arith.index_castui %6 : i32 to index
    %19 = arith.index_castui %7 : i32 to index
    %20 = arith.index_castui %8 : i32 to index
    %21 = arith.index_castui %9 : i32 to index
    %22 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%14) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %22, 64 : memref<400xf64, strided<[1], offset: ?>>
    %23 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%15) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %23, 1 : memref<400xf64, strided<[1], offset: ?>>
    %24 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%16) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %24, 1 : memref<400xf64, strided<[1], offset: ?>>
    %25 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%17) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %25, 1 : memref<400xf64, strided<[1], offset: ?>>
    %26 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%18) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %26, 1 : memref<400xf64, strided<[1], offset: ?>>
    %27 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%19) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %27, 1 : memref<400xf64, strided<[1], offset: ?>>
    %28 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%20) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %28, 1 : memref<400xf64, strided<[1], offset: ?>>
    %29 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%21) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %29, 1 : memref<400xf64, strided<[1], offset: ?>>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<400xf64>
    %cast = memref.cast %view : memref<400xf64> to memref<400xf64, strided<[1]>>
    %30 = dma.start_transfer from %22 : memref<400xf64, strided<[1], offset: ?>> to %cast : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %30
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c3200][] : memref<100000xi8> to memref<400xf64>
    %cast_1 = memref.cast %view_0 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %31 = dma.start_transfer from %23 : memref<400xf64, strided<[1], offset: ?>> to %cast_1 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %31
    quidditch_snitch.barrier
    %view_2 = memref.view %0[%c6400][] : memref<100000xi8> to memref<400xf64>
    %cast_3 = memref.cast %view_2 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %32 = dma.start_transfer from %24 : memref<400xf64, strided<[1], offset: ?>> to %cast_3 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %32
    quidditch_snitch.barrier
    %view_4 = memref.view %0[%c9600][] : memref<100000xi8> to memref<400xf64>
    %cast_5 = memref.cast %view_4 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %33 = dma.start_transfer from %25 : memref<400xf64, strided<[1], offset: ?>> to %cast_5 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %33
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c12800][] : memref<100000xi8> to memref<400xf64>
    %cast_7 = memref.cast %view_6 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %34 = dma.start_transfer from %26 : memref<400xf64, strided<[1], offset: ?>> to %cast_7 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %34
    quidditch_snitch.barrier
    %view_8 = memref.view %0[%c16000][] : memref<100000xi8> to memref<400xf64>
    %cast_9 = memref.cast %view_8 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %35 = dma.start_transfer from %27 : memref<400xf64, strided<[1], offset: ?>> to %cast_9 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %35
    quidditch_snitch.barrier
    %view_10 = memref.view %0[%c19200][] : memref<100000xi8> to memref<400xf64>
    %cast_11 = memref.cast %view_10 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %36 = dma.start_transfer from %28 : memref<400xf64, strided<[1], offset: ?>> to %cast_11 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %36
    quidditch_snitch.barrier
    %view_12 = memref.view %0[%c22400][] : memref<100000xi8> to memref<400xf64>
    %cast_13 = memref.cast %view_12 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %37 = dma.start_transfer from %29 : memref<400xf64, strided<[1], offset: ?>> to %cast_13 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %37
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %38 = dma.start_transfer from %view_12 : memref<400xf64> to %29 : memref<400xf64, strided<[1], offset: ?>>
    dma.wait_for_transfer %38
    quidditch_snitch.barrier
    return
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: 
RADDISH: (convertToRISCV) erasing the kernel op and continuing on...

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
"builtin.module"() ({
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_3_elementwise_400_f64"}> ({
    %64 = "arith.constant"() <{value = 22400 : index}> : () -> index
    %65 = "arith.constant"() <{value = 19200 : index}> : () -> index
    %66 = "arith.constant"() <{value = 16000 : index}> : () -> index
    %67 = "arith.constant"() <{value = 12800 : index}> : () -> index
    %68 = "arith.constant"() <{value = 9600 : index}> : () -> index
    %69 = "arith.constant"() <{value = 6400 : index}> : () -> index
    %70 = "arith.constant"() <{value = 3200 : index}> : () -> index
    %71 = "arith.constant"() <{value = 0 : index}> : () -> index
    %72 = "arith.constant"() <{value = 32 : i64}> : () -> i64
    %73 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %74 = "hal.interface.constant.load"() {index = 0 : index} : () -> i32
    %75 = "hal.interface.constant.load"() {index = 1 : index} : () -> i32
    %76 = "hal.interface.constant.load"() {index = 2 : index} : () -> i32
    %77 = "hal.interface.constant.load"() {index = 3 : index} : () -> i32
    %78 = "hal.interface.constant.load"() {index = 4 : index} : () -> i32
    %79 = "hal.interface.constant.load"() {index = 5 : index} : () -> i32
    %80 = "hal.interface.constant.load"() {index = 6 : index} : () -> i32
    %81 = "hal.interface.constant.load"() {index = 7 : index} : () -> i32
    %82 = "hal.interface.constant.load"() {index = 8 : index} : () -> i32
    %83 = "arith.extui"(%74) : (i32) -> i64
    %84 = "arith.extui"(%75) : (i32) -> i64
    %85 = "arith.shli"(%84, %72) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %86 = "arith.ori"(%83, %85) : (i64, i64) -> i64
    %87 = "arith.index_castui"(%86) {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : (i64) -> index
    %88 = "arith.index_castui"(%76) : (i32) -> index
    %89 = "arith.index_castui"(%77) : (i32) -> index
    %90 = "arith.index_castui"(%78) : (i32) -> index
    %91 = "arith.index_castui"(%79) : (i32) -> index
    %92 = "arith.index_castui"(%80) : (i32) -> index
    %93 = "arith.index_castui"(%81) : (i32) -> index
    %94 = "arith.index_castui"(%82) : (i32) -> index
    %95 = "hal.interface.binding.subspan"(%87) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%95) <{alignment = 64 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %96 = "hal.interface.binding.subspan"(%88) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%96) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %97 = "hal.interface.binding.subspan"(%89) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%97) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %98 = "hal.interface.binding.subspan"(%90) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%98) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %99 = "hal.interface.binding.subspan"(%91) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%99) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %100 = "hal.interface.binding.subspan"(%92) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%100) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %101 = "hal.interface.binding.subspan"(%93) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%101) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %102 = "hal.interface.binding.subspan"(%94) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%102) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %103 = "memref.view"(%73, %71) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %104 = "memref.view"(%73, %70) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %105 = "memref.view"(%73, %69) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %106 = "memref.view"(%73, %68) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %107 = "memref.view"(%73, %67) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %108 = "memref.view"(%73, %66) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %109 = "memref.view"(%73, %65) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %110 = "memref.view"(%73, %64) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %111 = "quidditch_snitch.compute_core_index"() : () -> index
    %112 = "affine.apply"(%111) <{map = affine_map<()[s0] -> (s0 * 50)>}> : (index) -> index
    %113 = "memref.subview"(%103, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %114 = "memref.subview"(%104, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %115 = "memref.subview"(%105, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %116 = "memref.subview"(%106, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %117 = "memref.subview"(%107, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %118 = "memref.subview"(%108, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %119 = "memref.subview"(%109, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %120 = "memref.subview"(%110, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %121 = "arith.constant"() <{value = 1.000000e+00 : f64}> : () -> f64
    "linalg.generic"(%113, %114, %115, %116, %117, %118, %119, %120) <{indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = [#linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 7, 1>}> ({
    ^bb0(%arg0: f64, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64, %arg5: f64, %arg6: f64, %arg7: f64):
      %122 = "arith.addf"(%arg5, %arg6) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %123 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %124 = "arith.negf"(%123) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %125 = "math.exp"(%124) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %126 = "arith.addf"(%125, %121) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %127 = "arith.divf"(%121, %126) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %128 = "arith.mulf"(%arg2, %127) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %129 = "arith.addf"(%arg1, %128) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %130 = "math.tanh"(%129) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %131 = "arith.negf"(%122) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %132 = "math.exp"(%131) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %133 = "arith.addf"(%132, %121) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %134 = "arith.divf"(%121, %133) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %135 = "arith.subf"(%arg0, %130) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %136 = "arith.mulf"(%135, %134) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %137 = "arith.addf"(%136, %130) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      "linalg.yield"(%137) : (f64) -> ()
    }) : (memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) -> ()
    "quidditch_snitch.memref.microkernel"(%113, %114, %115, %116, %117, %118, %119, %120) ({
    }) : (memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {quidditch_snitch.dma_specialization = @main$async_dispatch_3_elementwise_400_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_3_elementwise_400_f64$dma"}> ({
    %0 = "arith.constant"() <{value = 22400 : index}> : () -> index
    %1 = "arith.constant"() <{value = 19200 : index}> : () -> index
    %2 = "arith.constant"() <{value = 16000 : index}> : () -> index
    %3 = "arith.constant"() <{value = 12800 : index}> : () -> index
    %4 = "arith.constant"() <{value = 9600 : index}> : () -> index
    %5 = "arith.constant"() <{value = 6400 : index}> : () -> index
    %6 = "arith.constant"() <{value = 3200 : index}> : () -> index
    %7 = "arith.constant"() <{value = 0 : index}> : () -> index
    %8 = "arith.constant"() <{value = 32 : i64}> : () -> i64
    %9 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %10 = "hal.interface.constant.load"() {index = 0 : index} : () -> i32
    %11 = "hal.interface.constant.load"() {index = 1 : index} : () -> i32
    %12 = "hal.interface.constant.load"() {index = 2 : index} : () -> i32
    %13 = "hal.interface.constant.load"() {index = 3 : index} : () -> i32
    %14 = "hal.interface.constant.load"() {index = 4 : index} : () -> i32
    %15 = "hal.interface.constant.load"() {index = 5 : index} : () -> i32
    %16 = "hal.interface.constant.load"() {index = 6 : index} : () -> i32
    %17 = "hal.interface.constant.load"() {index = 7 : index} : () -> i32
    %18 = "hal.interface.constant.load"() {index = 8 : index} : () -> i32
    %19 = "arith.extui"(%10) : (i32) -> i64
    %20 = "arith.extui"(%11) : (i32) -> i64
    %21 = "arith.shli"(%20, %8) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %22 = "arith.ori"(%19, %21) : (i64, i64) -> i64
    %23 = "arith.index_castui"(%22) {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : (i64) -> index
    %24 = "arith.index_castui"(%12) : (i32) -> index
    %25 = "arith.index_castui"(%13) : (i32) -> index
    %26 = "arith.index_castui"(%14) : (i32) -> index
    %27 = "arith.index_castui"(%15) : (i32) -> index
    %28 = "arith.index_castui"(%16) : (i32) -> index
    %29 = "arith.index_castui"(%17) : (i32) -> index
    %30 = "arith.index_castui"(%18) : (i32) -> index
    %31 = "hal.interface.binding.subspan"(%23) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%31) <{alignment = 64 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %32 = "hal.interface.binding.subspan"(%24) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%32) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %33 = "hal.interface.binding.subspan"(%25) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%33) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %34 = "hal.interface.binding.subspan"(%26) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%34) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %35 = "hal.interface.binding.subspan"(%27) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%35) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %36 = "hal.interface.binding.subspan"(%28) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%36) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %37 = "hal.interface.binding.subspan"(%29) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%37) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %38 = "hal.interface.binding.subspan"(%30) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%38) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %39 = "memref.view"(%9, %7) : (memref<100000xi8>, index) -> memref<400xf64>
    %40 = "memref.cast"(%39) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %41 = "dma.start_transfer"(%31, %40) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%41) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %42 = "memref.view"(%9, %6) : (memref<100000xi8>, index) -> memref<400xf64>
    %43 = "memref.cast"(%42) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %44 = "dma.start_transfer"(%32, %43) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%44) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %45 = "memref.view"(%9, %5) : (memref<100000xi8>, index) -> memref<400xf64>
    %46 = "memref.cast"(%45) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %47 = "dma.start_transfer"(%33, %46) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%47) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %48 = "memref.view"(%9, %4) : (memref<100000xi8>, index) -> memref<400xf64>
    %49 = "memref.cast"(%48) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %50 = "dma.start_transfer"(%34, %49) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%50) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %51 = "memref.view"(%9, %3) : (memref<100000xi8>, index) -> memref<400xf64>
    %52 = "memref.cast"(%51) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %53 = "dma.start_transfer"(%35, %52) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%53) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %54 = "memref.view"(%9, %2) : (memref<100000xi8>, index) -> memref<400xf64>
    %55 = "memref.cast"(%54) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %56 = "dma.start_transfer"(%36, %55) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%56) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %57 = "memref.view"(%9, %1) : (memref<100000xi8>, index) -> memref<400xf64>
    %58 = "memref.cast"(%57) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %59 = "dma.start_transfer"(%37, %58) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%59) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %60 = "memref.view"(%9, %0) : (memref<100000xi8>, index) -> memref<400xf64>
    %61 = "memref.cast"(%60) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %62 = "dma.start_transfer"(%38, %61) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%62) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %63 = "dma.start_transfer"(%60, %38) : (memref<400xf64>, memref<400xf64, strided<[1], offset: ?>>) -> !dma.token
    "dma.wait_for_transfer"(%63) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
}) : () -> ()
failed to translate executables
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %6 = dma.start_transfer from %1 : memref<1x161xf64> to %cast : memref<1x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %12 = dma.start_transfer from %subview_17 : memref<40x161xf64, strided<[161, 1], offset: ?>> to %cast_7 : memref<40x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: RADDISH PROBLEM: type.getShape().front() = 40 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %12 = dma.start_transfer from %subview_17 : memref<40x161xf64, strided<[161, 1], offset: ?>> to %cast_7 : memref<40x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %9 = dma.start_transfer from %3 : memref<1x400xf64, strided<[400, 1], offset: 64400>> to %cast_10 : memref<1x400xf64, strided<[400, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %11 = dma.start_transfer from %4 : memref<1x400xf64> to %cast_15 : memref<1x400xf64, strided<[400, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %13 = dma.start_transfer from %reinterpret_cast_14 : memref<1x400xf64> to %4 : memref<1x400xf64>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %23 = dma.start_transfer from %subview_15 : memref<1x25xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x25xf64, strided<[25, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %20 = dma.start_transfer from %16 : memref<1x1200xf64, strided<[1200, 1], offset: ?>> to %cast_8 : memref<1x1200xf64, strided<[1200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %22 = dma.start_transfer from %17 : memref<1x1200xf64, strided<[1200, 1], offset: ?>> to %cast_13 : memref<1x1200xf64, strided<[1200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %24 = dma.start_transfer from %reinterpret_cast_12 : memref<1x1200xf64> to %17 : memref<1x1200xf64, strided<[1200, 1], offset: ?>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:96:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:96:0: note: see current operation: %11 = dma.start_transfer from %subview_18 : memref<1x100xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %8 = dma.start_transfer from %3 : memref<1x600xf64, strided<[600, 1], offset: 2229600>> to %cast_11 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %10 = dma.start_transfer from %4 : memref<1x600xf64> to %cast_16 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %12 = dma.start_transfer from %reinterpret_cast_15 : memref<1x600xf64> to %4 : memref<1x600xf64>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: note: see current operation: %10 = dma.start_transfer from %subview_16 : memref<1x200xf64, strided<[600, 1], offset: ?>> to %cast : memref<1x200xf64, strided<[200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %7 = dma.start_transfer from %3 : memref<1x600xf64, strided<[600, 1], offset: 2590200>> to %cast_8 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %9 = dma.start_transfer from %4 : memref<1x600xf64, strided<[600, 1], offset: 600>> to %cast_13 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %11 = dma.start_transfer from %reinterpret_cast_12 : memref<1x600xf64> to %4 : memref<1x600xf64, strided<[600, 1], offset: 600>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: error: failed to legalize operation 'quidditch_snitch.call_microkernel' that was explicitly marked illegal
/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: note: see current operation: "quidditch_snitch.call_microkernel"(%133, %223, %265) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:\0A    mv t1, a0\0A    mv t0, a1\0A    li t2, 199\0A    scfgwi t2, 64                                # dm 0 dim 0 bound\0A    li t2, -2\0A    scfgwi t2, 96                                # dm 0 dim 1 bound\0A    li t2, 8\0A    scfgwi t2, 192                               # dm 0 dim 0 stride\0A    li t2, -1592\0A    scfgwi t2, 224                               # dm 0 dim 1 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    li t2, -201\0A    scfgwi t2, 65                                # dm 1 dim 0 bound\0A    li t2, 8\0A    scfgwi t2, 193                               # dm 1 dim 0 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t1, 800                               # dm 0 dim 1 source\0A    scfgwi t0, 769                               # dm 1 dim 0 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>) -> ()
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH (q-convert-to-llvm) applyPartialConversion failed :'(
/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: 
module attributes {llvm.data_layout = "e-m:e-p:32:32-i64:64-n32-S128", llvm.target_triple = "riscv32-unknown-elf"} {
  func.func @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c59200 = arith.constant 59200 : index
    %c54400 = arith.constant 54400 : index
    %c6400 = arith.constant 6400 : index
    %c4800 = arith.constant 4800 : index
    %c0 = arith.constant 0 : index
    %c600 = arith.constant 600 : index
    %c30 = arith.constant 30 : index
    %c200 = arith.constant 200 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %1 = quidditch_snitch.compute_core_index
    %2 = affine.apply affine_map<()[s0] -> (s0 * 75)>()[%1]
    %subview = memref.subview %reinterpret_cast[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0"(%subview) : memref<1x75xf64, strided<[600, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0"
      ".p2align 2"
      "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0:"
      "    mv t0, a0"
      "    fcvt.d.w ft3, zero"
      "    li t1, 74"
      "    scfgwi t1, 64                                # dm 0 dim 0 bound"
      "    li t1, 8"
      "    scfgwi t1, 192                               # dm 0 dim 0 stride"
      "    scfgwi zero, 32                              # dm 0 repeat"
      "    scfgwi t0, 896                               # dm 0 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 74"
      "    frep.o t0, 1, 0, 0"
      "    fmv.d ft0, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c4800][] : memref<100000xi8> to memref<200xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [1, 200], strides: [200, 1] : memref<200xf64> to memref<1x200xf64>
    %view_2 = memref.view %0[%c6400][] : memref<100000xi8> to memref<6000xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [30, 200], strides: [200, 1] : memref<6000xf64> to memref<30x200xf64>
    %3 = affine.apply affine_map<()[s0] -> (s0 * 4)>()[%1]
    scf.for %arg0 = %c0 to %c600 step %c30 {
      scf.for %arg1 = %c0 to %c600 step %c200 {
        quidditch_snitch.barrier
        quidditch_snitch.barrier
        %4 = affine.min affine_map<()[s0] -> (s0 * -4 + 30, 4)>()[%1]
        %subview_10 = memref.subview %reinterpret_cast_3[%3, 0] [%4, 200] [1, 1] : memref<30x200xf64> to memref<?x200xf64, strided<[200, 1], offset: ?>>
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 4)>()[%arg0, %1]
        %subview_11 = memref.subview %reinterpret_cast[0, %5] [1, %4] [1, 1] : memref<1x600xf64> to memref<1x?xf64, strided<[600, 1], offset: ?>>
        quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1"(%reinterpret_cast_1, %subview_10, %subview_11) : memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>[{
          ".text"
          ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1"
          ".p2align 2"
          "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:"
          "    mv t1, a0"
          "    mv t0, a1"
          "    li t2, 199"
          "    scfgwi t2, 64                                # dm 0 dim 0 bound"
          "    li t2, -2"
          "    scfgwi t2, 96                                # dm 0 dim 1 bound"
          "    li t2, 8"
          "    scfgwi t2, 192                               # dm 0 dim 0 stride"
          "    li t2, -1592"
          "    scfgwi t2, 224                               # dm 0 dim 1 stride"
          "    scfgwi zero, 32                              # dm 0 repeat"
          "    li t2, -201"
          "    scfgwi t2, 65                                # dm 1 dim 0 bound"
          "    li t2, 8"
          "    scfgwi t2, 193                               # dm 1 dim 0 stride"
          "    scfgwi zero, 33                              # dm 1 repeat"
          "    scfgwi t1, 800                               # dm 0 dim 1 source"
          "    scfgwi t0, 769                               # dm 1 dim 0 source"
          "    csrrsi zero, 1984, 1                         # SSR enable"
          "    csrrci zero, 1984, 1                         # SSR disable"
          "    ret"
          ""
        }]
        quidditch_snitch.microkernel_fence
        quidditch_snitch.barrier
      }
    }
    %view_4 = memref.view %0[%c54400][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c59200][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_7 = memref.reinterpret_cast %view_6 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    quidditch_snitch.barrier
    %subview_8 = memref.subview %reinterpret_cast_5[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    %subview_9 = memref.subview %reinterpret_cast_7[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2"(%subview, %subview_8, %subview_9) : memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2"
      ".p2align 2"
      "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2:"
      "    mv t2, a0"
      "    mv t1, a1"
      "    mv t0, a2"
      "    fcvt.d.w ft3, zero"
      "    li t3, 74"
      "    scfgwi t3, 95                                # dm 31 dim 0 bound"
      "    li t3, 8"
      "    scfgwi t3, 223                               # dm 31 dim 0 stride"
      "    scfgwi zero, 63                              # dm 31 repeat"
      "    scfgwi t2, 768                               # dm 0 dim 0 source"
      "    scfgwi t1, 769                               # dm 1 dim 0 source"
      "    scfgwi t0, 898                               # dm 2 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 74"
      "    frep.o t0, 2, 0, 0"
      "    fadd.d ft4, ft0, ft1"
      "    fmax.d ft2, ft4, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c59200 = arith.constant 59200 : index
    %c54400 = arith.constant 54400 : index
    %c6400 = arith.constant 6400 : index
    %c4800 = arith.constant 4800 : index
    %c20721600 = arith.constant 20721600 : index
    %c17841600 = arith.constant 17841600 : index
    %c0 = arith.constant 0 : index
    %c600 = arith.constant 600 : index
    %c30 = arith.constant 30 : index
    %c200 = arith.constant 200 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x600xf64>
    memref.assume_alignment %1, 64 : memref<1x600xf64>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c17841600) flags(ReadOnly) : memref<600x600xf64, strided<[600, 1], offset: 2230200>>
    memref.assume_alignment %2, 64 : memref<600x600xf64, strided<[600, 1], offset: 2230200>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20721600) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 2590200>>
    memref.assume_alignment %3, 64 : memref<1x600xf64, strided<[600, 1], offset: 2590200>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c4800) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %4, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    quidditch_snitch.barrier
    %view = memref.view %0[%c4800][] : memref<100000xi8> to memref<200xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 200], strides: [200, 1] : memref<200xf64> to memref<1x200xf64>
    %view_0 = memref.view %0[%c6400][] : memref<100000xi8> to memref<6000xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [30, 200], strides: [200, 1] : memref<6000xf64> to memref<30x200xf64>
    %cast = memref.cast %reinterpret_cast_1 : memref<30x200xf64> to memref<30x200xf64, strided<[200, 1]>>
    scf.for %arg0 = %c0 to %c600 step %c30 {
      scf.for %arg1 = %c0 to %c600 step %c200 {
        %subview_9 = memref.subview %2[%arg0, %arg1] [30, 200] [1, 1] : memref<600x600xf64, strided<[600, 1], offset: 2230200>> to memref<30x200xf64, strided<[600, 1], offset: ?>>
        %subview_10 = memref.subview %1[0, %arg1] [1, 200] [1, 1] : memref<1x600xf64> to memref<200xf64, strided<[1], offset: ?>>
        %subview_11 = memref.subview %reinterpret_cast[0, 0] [1, 200] [1, 1] : memref<1x200xf64> to memref<200xf64, strided<[1]>>
        %8 = dma.start_transfer from %subview_10 : memref<200xf64, strided<[1], offset: ?>> to %subview_11 : memref<200xf64, strided<[1]>>
        dma.wait_for_transfer %8
        quidditch_snitch.barrier
        %9 = dma.start_transfer from %subview_9 : memref<30x200xf64, strided<[600, 1], offset: ?>> to %cast : memref<30x200xf64, strided<[200, 1]>>
        dma.wait_for_transfer %9
        quidditch_snitch.barrier
        quidditch_snitch.barrier
      }
    }
    %view_2 = memref.view %0[%c54400][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %subview = memref.subview %3[0, 0] [1, 600] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 2590200>> to memref<600xf64, strided<[1], offset: 2590200>>
    %subview_4 = memref.subview %reinterpret_cast_3[0, 0] [1, 600] [1, 1] : memref<1x600xf64> to memref<600xf64, strided<[1]>>
    %5 = dma.start_transfer from %subview : memref<600xf64, strided<[1], offset: 2590200>> to %subview_4 : memref<600xf64, strided<[1]>>
    dma.wait_for_transfer %5
    quidditch_snitch.barrier
    %view_5 = memref.view %0[%c59200][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_6 = memref.reinterpret_cast %view_5 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %subview_7 = memref.subview %4[0, 0] [1, 600] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 600>> to memref<600xf64, strided<[1], offset: 600>>
    %subview_8 = memref.subview %reinterpret_cast_6[0, 0] [1, 600] [1, 1] : memref<1x600xf64> to memref<600xf64, strided<[1]>>
    %6 = dma.start_transfer from %subview_7 : memref<600xf64, strided<[1], offset: 600>> to %subview_8 : memref<600xf64, strided<[1]>>
    dma.wait_for_transfer %6
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %7 = dma.start_transfer from %subview_8 : memref<600xf64, strided<[1]>> to %subview_7 : memref<600xf64, strided<[1], offset: 600>>
    dma.wait_for_transfer %7
    quidditch_snitch.barrier
    return
  }
  llvm.func @snrt_cluster_core_idx() -> i32 attributes {hal.import.bitcode}
  llvm.func @snrt_dma_start_1d(!llvm.ptr, !llvm.ptr, i32) -> i32 attributes {hal.import.bitcode}
  llvm.func @snrt_dma_start_2d(!llvm.ptr, !llvm.ptr, i32, i32, i32, i32) -> i32 attributes {hal.import.bitcode}
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: error: failed to run translation of source executable to target executable for backend #hal.executable.target<"quidditch", "static", {compute_cores = 8 : i32, data_layout = "e-m:e-p:32:32-i64:64-n32-S128", target_triple = "riscv32-unknown-elf"}>
/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: 
"hal.executable.variant"() ({
  "hal.executable.export"() ({
  ^bb0(%arg4: !hal.device):
    %65 = "arith.constant"() <{value = 1 : index}> : () -> index
    "hal.return"(%65, %65, %65) : (index, index, index) -> ()
  }) {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>], layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>, ordinal = 0 : index, sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64"} : () -> ()
  "builtin.module"() ({
    "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64"}> ({
      %36 = "arith.constant"() <{value = 59200 : index}> : () -> index
      %37 = "arith.constant"() <{value = 54400 : index}> : () -> index
      %38 = "arith.constant"() <{value = 6400 : index}> : () -> index
      %39 = "arith.constant"() <{value = 4800 : index}> : () -> index
      %40 = "arith.constant"() <{value = 0 : index}> : () -> index
      %41 = "arith.constant"() <{value = 600 : index}> : () -> index
      %42 = "arith.constant"() <{value = 30 : index}> : () -> index
      %43 = "arith.constant"() <{value = 200 : index}> : () -> index
      %44 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
      %45 = "memref.view"(%44, %40) : (memref<100000xi8>, index) -> memref<600xf64>
      %46 = "memref.reinterpret_cast"(%45) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %47 = "quidditch_snitch.compute_core_index"() : () -> index
      %48 = "affine.apply"(%47) <{map = affine_map<()[s0] -> (s0 * 75)>}> : (index) -> index
      %49 = "memref.subview"(%46, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%49) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0:\0A    mv t0, a0\0A    fcvt.d.w ft3, zero\0A    li t1, 74\0A    scfgwi t1, 64                                # dm 0 dim 0 bound\0A    li t1, 8\0A    scfgwi t1, 192                               # dm 0 dim 0 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    scfgwi t0, 896                               # dm 0 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 74\0A    frep.o t0, 1, 0, 0\0A    fmv.d ft0, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x75xf64, strided<[600, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %50 = "memref.view"(%44, %39) : (memref<100000xi8>, index) -> memref<200xf64>
      %51 = "memref.reinterpret_cast"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 200, 1>}> : (memref<200xf64>) -> memref<1x200xf64>
      %52 = "memref.view"(%44, %38) : (memref<100000xi8>, index) -> memref<6000xf64>
      %53 = "memref.reinterpret_cast"(%52) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 200, 1>}> : (memref<6000xf64>) -> memref<30x200xf64>
      %54 = "affine.apply"(%47) <{map = affine_map<()[s0] -> (s0 * 4)>}> : (index) -> index
      "scf.for"(%40, %41, %42) ({
      ^bb0(%arg2: index):
        "scf.for"(%40, %41, %43) ({
        ^bb0(%arg3: index):
          "quidditch_snitch.barrier"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          %61 = "affine.min"(%47) <{map = affine_map<()[s0] -> (s0 * -4 + 30, 4)>}> : (index) -> index
          %62 = "memref.subview"(%53, %54, %61) <{operandSegmentSizes = array<i32: 1, 1, 1, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: -9223372036854775808, 200>, static_strides = array<i64: 1, 1>}> : (memref<30x200xf64>, index, index) -> memref<?x200xf64, strided<[200, 1], offset: ?>>
          %63 = "affine.apply"(%arg2, %47) <{map = affine_map<()[s0, s1] -> (s0 + s1 * 4)>}> : (index, index) -> index
          %64 = "memref.subview"(%46, %63, %61) <{operandSegmentSizes = array<i32: 1, 1, 1, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, -9223372036854775808>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index, index) -> memref<1x?xf64, strided<[600, 1], offset: ?>>
          "quidditch_snitch.call_microkernel"(%51, %62, %64) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:\0A    mv t1, a0\0A    mv t0, a1\0A    li t2, 199\0A    scfgwi t2, 64                                # dm 0 dim 0 bound\0A    li t2, -2\0A    scfgwi t2, 96                                # dm 0 dim 1 bound\0A    li t2, 8\0A    scfgwi t2, 192                               # dm 0 dim 0 stride\0A    li t2, -1592\0A    scfgwi t2, 224                               # dm 0 dim 1 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    li t2, -201\0A    scfgwi t2, 65                                # dm 1 dim 0 bound\0A    li t2, 8\0A    scfgwi t2, 193                               # dm 1 dim 0 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t1, 800                               # dm 0 dim 1 source\0A    scfgwi t0, 769                               # dm 1 dim 0 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>) -> ()
          "quidditch_snitch.microkernel_fence"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "scf.yield"() : () -> ()
        }) : (index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      %55 = "memref.view"(%44, %37) : (memref<100000xi8>, index) -> memref<600xf64>
      %56 = "memref.reinterpret_cast"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %57 = "memref.view"(%44, %36) : (memref<100000xi8>, index) -> memref<600xf64>
      %58 = "memref.reinterpret_cast"(%57) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %59 = "memref.subview"(%56, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      %60 = "memref.subview"(%58, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%49, %59, %60) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    fcvt.d.w ft3, zero\0A    li t3, 74\0A    scfgwi t3, 95                                # dm 31 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 223                               # dm 31 dim 0 stride\0A    scfgwi zero, 63                              # dm 31 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 769                               # dm 1 dim 0 source\0A    scfgwi t0, 898                               # dm 2 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 74\0A    frep.o t0, 2, 0, 0\0A    fadd.d ft4, ft0, ft1\0A    fmax.d ft2, ft4, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "func.return"() : () -> ()
    }) {quidditch_snitch.dma_specialization = @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
    "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma"}> ({
      %0 = "arith.constant"() <{value = 59200 : index}> : () -> index
      %1 = "arith.constant"() <{value = 54400 : index}> : () -> index
      %2 = "arith.constant"() <{value = 6400 : index}> : () -> index
      %3 = "arith.constant"() <{value = 4800 : index}> : () -> index
      %4 = "arith.constant"() <{value = 20721600 : index}> : () -> index
      %5 = "arith.constant"() <{value = 17841600 : index}> : () -> index
      %6 = "arith.constant"() <{value = 0 : index}> : () -> index
      %7 = "arith.constant"() <{value = 600 : index}> : () -> index
      %8 = "arith.constant"() <{value = 30 : index}> : () -> index
      %9 = "arith.constant"() <{value = 200 : index}> : () -> index
      %10 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
      %11 = "hal.interface.binding.subspan"(%6) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64>
      "memref.assume_alignment"(%11) <{alignment = 64 : i32}> : (memref<1x600xf64>) -> ()
      %12 = "hal.interface.binding.subspan"(%5) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<600x600xf64, strided<[600, 1], offset: 2230200>>
      "memref.assume_alignment"(%12) <{alignment = 64 : i32}> : (memref<600x600xf64, strided<[600, 1], offset: 2230200>>) -> ()
      %13 = "hal.interface.binding.subspan"(%4) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 2590200>>
      "memref.assume_alignment"(%13) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 2590200>>) -> ()
      %14 = "hal.interface.binding.subspan"(%3) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
      "memref.assume_alignment"(%14) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %15 = "memref.view"(%10, %3) : (memref<100000xi8>, index) -> memref<200xf64>
      %16 = "memref.reinterpret_cast"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 200, 1>}> : (memref<200xf64>) -> memref<1x200xf64>
      %17 = "memref.view"(%10, %2) : (memref<100000xi8>, index) -> memref<6000xf64>
      %18 = "memref.reinterpret_cast"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 200, 1>}> : (memref<6000xf64>) -> memref<30x200xf64>
      %19 = "memref.cast"(%18) : (memref<30x200xf64>) -> memref<30x200xf64, strided<[200, 1]>>
      "scf.for"(%6, %7, %8) ({
      ^bb0(%arg0: index):
        "scf.for"(%6, %7, %9) ({
        ^bb0(%arg1: index):
          %31 = "memref.subview"(%12, %arg0, %arg1) <{operandSegmentSizes = array<i32: 1, 2, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 1, 1>}> : (memref<600x600xf64, strided<[600, 1], offset: 2230200>>, index, index) -> memref<30x200xf64, strided<[600, 1], offset: ?>>
          %32 = "memref.subview"(%11, %arg1) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<200xf64, strided<[1], offset: ?>>
          %33 = "memref.subview"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 1, 1>}> : (memref<1x200xf64>) -> memref<200xf64, strided<[1]>>
          %34 = "dma.start_transfer"(%32, %33) : (memref<200xf64, strided<[1], offset: ?>>, memref<200xf64, strided<[1]>>) -> !dma.token
          "dma.wait_for_transfer"(%34) : (!dma.token) -> ()
          "quidditch_snitch.barrier"() : () -> ()
          %35 = "dma.start_transfer"(%31, %19) : (memref<30x200xf64, strided<[600, 1], offset: ?>>, memref<30x200xf64, strided<[200, 1]>>) -> !dma.token
          "dma.wait_for_transfer"(%35) : (!dma.token) -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "scf.yield"() : () -> ()
        }) : (index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      %20 = "memref.view"(%10, %1) : (memref<100000xi8>, index) -> memref<600xf64>
      %21 = "memref.reinterpret_cast"(%20) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %22 = "memref.subview"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 2590200>>) -> memref<600xf64, strided<[1], offset: 2590200>>
      %23 = "memref.subview"(%21) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>) -> memref<600xf64, strided<[1]>>
      %24 = "dma.start_transfer"(%22, %23) : (memref<600xf64, strided<[1], offset: 2590200>>, memref<600xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%24) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %25 = "memref.view"(%10, %0) : (memref<100000xi8>, index) -> memref<600xf64>
      %26 = "memref.reinterpret_cast"(%25) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %27 = "memref.subview"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> memref<600xf64, strided<[1], offset: 600>>
      %28 = "memref.subview"(%26) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>) -> memref<600xf64, strided<[1]>>
      %29 = "dma.start_transfer"(%27, %28) : (memref<600xf64, strided<[1], offset: 600>>, memref<600xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%29) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %30 = "dma.start_transfer"(%28, %27) : (memref<600xf64, strided<[1]>>, memref<600xf64, strided<[1], offset: 600>>) -> !dma.token
      "dma.wait_for_transfer"(%30) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "func.return"() : () -> ()
    }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 ()>, linkage = #llvm.linkage<external>, sym_name = "snrt_cluster_core_idx", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 (ptr, ptr, i32)>, linkage = #llvm.linkage<external>, sym_name = "snrt_dma_start_1d", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 (ptr, ptr, i32, i32, i32, i32)>, linkage = #llvm.linkage<external>, sym_name = "snrt_dma_start_2d", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
  }) {llvm.data_layout = "e-m:e-p:32:32-i64:64-n32-S128", llvm.target_triple = "riscv32-unknown-elf"} : () -> ()
  "hal.executable.variant_end"() : () -> ()
}) {sym_name = "static", target = #hal.executable.target<"quidditch", "static", {compute_cores = 8 : i32, data_layout = "e-m:e-p:32:32-i64:64-n32-S128", target_triple = "riscv32-unknown-elf"}>} : () -> ()
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:110:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:110:0: note: see current operation: %11 = dma.start_transfer from %subview_18 : memref<1x100xf64, strided<[600, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %8 = dma.start_transfer from %3 : memref<1x161xf64, strided<[161, 1], offset: 2687400>> to %subview_11 : memref<1x161xf64, strided<[168, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %10 = dma.start_transfer from %4 : memref<1x161xf64> to %subview_16 : memref<1x161xf64, strided<[168, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %12 = dma.start_transfer from %subview_16 : memref<1x161xf64, strided<[168, 1]>> to %4 : memref<1x161xf64>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: Failed to translate kernel with xDSL
/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
quidditch_snitch.memref.microkernel(<<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>) : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>> {
^bb0(%arg0: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg1: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg2: memref<1x21xf64, strided<[168, 1], offset: ?>>):
  %cst = arith.constant 1.000000e+00 : f64
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) outs(%arg2 : memref<1x21xf64, strided<[168, 1], offset: ?>>) {
  ^bb0(%in: f64, %in_0: f64, %out: f64):
    %0 = arith.addf %in, %in_0 : f64
    %1 = arith.negf %0 : f64
    %2 = math.exp %1 : f64
    %3 = arith.addf %2, %cst : f64
    %4 = arith.divf %cst, %3 : f64
    linalg.yield %4 : f64
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: stderr:
Traceback (most recent call last):
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 534, in parse_chunk
    return self.available_frontends[file_extension](chunk)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 520, in parse_mlir
    ).parse_module(not self.args.no_implicit_module)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 127, in parse_module
    if (parsed_op := self.parse_optional_operation()) is not None:
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/func.py", line 138, in parse
    ) = parse_func_op_like(
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/utils.py", line 239, in parse_func_op_like
    region = parser.parse_optional_region(entry_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 539, in parse_optional_region
    self._parse_block_body(entry_block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/linalg.py", line 354, in parse
    body = parser.parse_region()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 594, in parse_region
    region = self.parse_optional_region(arguments)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 558, in parse_optional_region
    block = self._parse_block()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 247, in _parse_block
    self._parse_block_body(block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/ir/core.py", line 869, in parse
    parser.raise_error(f"Operation {cls.name} does not have a custom format.")
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/base_parser.py", line 107, in raise_error
    raise ParseError(at_position, msg)
xdsl.utils.exceptions.ParseError: stdin:7:18
    %2 = math.exp %1 : f64
                  ^^
                  Operation math.exp does not have a custom format.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hoppip/Quidditch/venv/bin/xdsl-opt", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/xdsl_opt.py", line 5, in main
    xDSLOptMain().run()
  File "/home/hoppip/Quidditch/xdsl/xdsl/xdsl_opt_main.py", line 71, in run
    module = self.parse_chunk(chunk, file_extension, offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 541, in parse_chunk
    raise Exception("Failed to parse:\n" + e.with_context()) from e
Exception: Failed to parse:
stdin:7:18
    %2 = math.exp %1 : f64
                  ^^
                  Operation math.exp does not have a custom format.


<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (convertToRISCV) convert to RISCV assembly failed

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
module {
  func.func @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c93120 = arith.constant 93120 : index
    %c91776 = arith.constant 91776 : index
    %c46976 = arith.constant 46976 : index
    %c2176 = arith.constant 2176 : index
    %c1344 = arith.constant 1344 : index
    %c0 = arith.constant 0 : index
    %c21499200 = arith.constant 21499200 : index
    %c20726400 = arith.constant 20726400 : index
    %c4800 = arith.constant 4800 : index
    %c600 = arith.constant 600 : index
    %c100 = arith.constant 100 : index
    %c168 = arith.constant 168 : index
    %c56 = arith.constant 56 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c4800) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %1, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20726400) flags(ReadOnly) : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    memref.assume_alignment %2, 64 : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c21499200) flags(ReadOnly) : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    memref.assume_alignment %3, 64 : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x161xf64>
    memref.assume_alignment %4, 64 : memref<1x161xf64>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %5 = quidditch_snitch.compute_core_index
    %6 = affine.apply affine_map<()[s0] -> (s0 * 21)>()[%5]
    %subview = memref.subview %reinterpret_cast[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0"(%subview) : memref<1x21xf64, strided<[168, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0"
      ".p2align 2"
      "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0:"
      "    mv t0, a0"
      "    fcvt.d.w ft3, zero"
      "    li t1, 20"
      "    scfgwi t1, 64                                # dm 0 dim 0 bound"
      "    li t1, 8"
      "    scfgwi t1, 192                               # dm 0 dim 0 stride"
      "    scfgwi zero, 32                              # dm 0 repeat"
      "    scfgwi t0, 896                               # dm 0 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 20"
      "    frep.o t0, 1, 0, 0"
      "    fmv.d ft0, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c1344][] : memref<100000xi8> to memref<100xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [1, 100], strides: [100, 1] : memref<100xf64> to memref<1x100xf64>
    %view_2 = memref.view %0[%c2176][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %view_4 = memref.view %0[%c46976][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %7 = affine.apply affine_map<()[s0] -> (s0 * 7)>()[%5]
    %subview_6 = memref.subview %reinterpret_cast[0, 112] [1, 56] [1, 1] : memref<1x168xf64> to memref<1x56xf64, strided<[168, 1], offset: 112>>
    scf.for %arg0 = %c0 to %c600 step %c100 {
      quidditch_snitch.barrier
      %8 = scf.for %arg1 = %c56 to %c168 step %c56 iter_args(%arg2 = %reinterpret_cast_3) -> (memref<56x100xf64>) {
        %9 = affine.apply affine_map<(d0) -> ((d0 floordiv 56) mod 2)>(%arg1)
        %10 = scf.index_switch %9 -> memref<56x100xf64> 
        case 0 {
          scf.yield %reinterpret_cast_3 : memref<56x100xf64>
        }
        default {
          scf.yield %reinterpret_cast_5 : memref<56x100xf64>
        }
        %11 = affine.apply affine_map<(d0) -> (d0 - 56)>(%arg1)
        %subview_15 = memref.subview %reinterpret_cast[0, %11] [1, 56] [1, 1] : memref<1x168xf64> to memref<1x56xf64, strided<[168, 1], offset: ?>>
        quidditch_snitch.barrier
        %subview_16 = memref.subview %arg2[%7, 0] [7, 100] [1, 1] : memref<56x100xf64> to memref<7x100xf64, strided<[100, 1], offset: ?>>
        %subview_17 = memref.subview %subview_15[0, %7] [1, 7] [1, 1] : memref<1x56xf64, strided<[168, 1], offset: ?>> to memref<1x7xf64, strided<[168, 1], offset: ?>>
        quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1"(%reinterpret_cast_1, %subview_16, %subview_17) : memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>[{
          ".text"
          ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1"
          ".p2align 2"
          "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1:"
          "    mv t2, a0"
          "    mv t1, a1"
          "    mv t0, a2"
          "    li t3, 99"
          "    scfgwi t3, 64                                # dm 0 dim 0 bound"
          "    li t3, 8"
          "    scfgwi t3, 192                               # dm 0 dim 0 stride"
          "    li t3, 6"
          "    scfgwi t3, 32                                # dm 0 repeat"
          "    li t3, 6"
          "    scfgwi t3, 65                                # dm 1 dim 0 bound"
          "    li t3, 99"
          "    scfgwi t3, 97                                # dm 1 dim 1 bound"
          "    li t3, 800"
          "    scfgwi t3, 193                               # dm 1 dim 0 stride"
          "    li t3, -4792"
          "    scfgwi t3, 225                               # dm 1 dim 1 stride"
          "    scfgwi zero, 33                              # dm 1 repeat"
          "    scfgwi t2, 768                               # dm 0 dim 0 source"
          "    scfgwi t1, 801                               # dm 1 dim 1 source"
          "    csrrsi zero, 1984, 1                         # SSR enable"
          "    mv t1, t0"
          "    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)"
          "    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)"
          "    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)"
          "    li t1, 99"
          "    frep.o t1, 7, 0, 0"
          "    fmadd.d ft9, ft0, ft1, ft9"
          "    fmadd.d ft8, ft0, ft1, ft8"
          "    fmadd.d ft7, ft0, ft1, ft7"
          "    fmadd.d ft6, ft0, ft1, ft6"
          "    fmadd.d ft5, ft0, ft1, ft5"
          "    fmadd.d ft4, ft0, ft1, ft4"
          "    fmadd.d ft3, ft0, ft1, ft3"
          "    mv t1, t0"
          "    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)"
          "    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)"
          "    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)"
          "    csrrci zero, 1984, 1                         # SSR disable"
          "    ret"
          ""
        }]
        quidditch_snitch.microkernel_fence
        quidditch_snitch.barrier
        scf.yield %10 : memref<56x100xf64>
      }
      quidditch_snitch.barrier
      %subview_13 = memref.subview %8[%7, 0] [7, 100] [1, 1] : memref<56x100xf64> to memref<7x100xf64, strided<[100, 1], offset: ?>>
      %subview_14 = memref.subview %subview_6[0, %7] [1, 7] [1, 1] : memref<1x56xf64, strided<[168, 1], offset: 112>> to memref<1x7xf64, strided<[168, 1], offset: ?>>
      quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2"(%reinterpret_cast_1, %subview_13, %subview_14) : memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>[{
        ".text"
        ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2"
        ".p2align 2"
        "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2:"
        "    mv t2, a0"
        "    mv t1, a1"
        "    mv t0, a2"
        "    li t3, 99"
        "    scfgwi t3, 64                                # dm 0 dim 0 bound"
        "    li t3, 8"
        "    scfgwi t3, 192                               # dm 0 dim 0 stride"
        "    li t3, 6"
        "    scfgwi t3, 32                                # dm 0 repeat"
        "    li t3, 6"
        "    scfgwi t3, 65                                # dm 1 dim 0 bound"
        "    li t3, 99"
        "    scfgwi t3, 97                                # dm 1 dim 1 bound"
        "    li t3, 800"
        "    scfgwi t3, 193                               # dm 1 dim 0 stride"
        "    li t3, -4792"
        "    scfgwi t3, 225                               # dm 1 dim 1 stride"
        "    scfgwi zero, 33                              # dm 1 repeat"
        "    scfgwi t2, 768                               # dm 0 dim 0 source"
        "    scfgwi t1, 801                               # dm 1 dim 1 source"
        "    csrrsi zero, 1984, 1                         # SSR enable"
        "    mv t1, t0"
        "    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)"
        "    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)"
        "    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)"
        "    li t1, 99"
        "    frep.o t1, 7, 0, 0"
        "    fmadd.d ft9, ft0, ft1, ft9"
        "    fmadd.d ft8, ft0, ft1, ft8"
        "    fmadd.d ft7, ft0, ft1, ft7"
        "    fmadd.d ft6, ft0, ft1, ft6"
        "    fmadd.d ft5, ft0, ft1, ft5"
        "    fmadd.d ft4, ft0, ft1, ft4"
        "    fmadd.d ft3, ft0, ft1, ft3"
        "    mv t1, t0"
        "    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)"
        "    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)"
        "    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)"
        "    csrrci zero, 1984, 1                         # SSR disable"
        "    ret"
        ""
      }]
      quidditch_snitch.microkernel_fence
      quidditch_snitch.barrier
    }
    %view_7 = memref.view %0[%c91776][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_8 = memref.reinterpret_cast %view_7 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    quidditch_snitch.barrier
    %view_9 = memref.view %0[%c93120][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_10 = memref.reinterpret_cast %view_9 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    quidditch_snitch.barrier
    %subview_11 = memref.subview %reinterpret_cast_8[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    %subview_12 = memref.subview %reinterpret_cast_10[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    quidditch_snitch.memref.microkernel(%subview, %subview_11, %subview_12) : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>> {
    ^bb0(%arg0: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg1: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg2: memref<1x21xf64, strided<[168, 1], offset: ?>>):
      %cst = arith.constant 1.000000e+00 : f64
      linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) outs(%arg2 : memref<1x21xf64, strided<[168, 1], offset: ?>>) {
      ^bb0(%in: f64, %in_13: f64, %out: f64):
        %8 = arith.addf %in, %in_13 : f64
        %9 = arith.negf %8 : f64
        %10 = math.exp %9 : f64
        %11 = arith.addf %10, %cst : f64
        %12 = arith.divf %cst, %11 : f64
        linalg.yield %12 : f64
      }
    }
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c93120 = arith.constant 93120 : index
    %c91776 = arith.constant 91776 : index
    %c46976 = arith.constant 46976 : index
    %c2176 = arith.constant 2176 : index
    %c1344 = arith.constant 1344 : index
    %c0 = arith.constant 0 : index
    %c21499200 = arith.constant 21499200 : index
    %c20726400 = arith.constant 20726400 : index
    %c4800 = arith.constant 4800 : index
    %c600 = arith.constant 600 : index
    %c100 = arith.constant 100 : index
    %c168 = arith.constant 168 : index
    %c56 = arith.constant 56 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c4800) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %1, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20726400) flags(ReadOnly) : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    memref.assume_alignment %2, 64 : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c21499200) flags(ReadOnly) : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    memref.assume_alignment %3, 64 : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x161xf64>
    memref.assume_alignment %4, 64 : memref<1x161xf64>
    quidditch_snitch.barrier
    %view = memref.view %0[%c1344][] : memref<100000xi8> to memref<100xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 100], strides: [100, 1] : memref<100xf64> to memref<1x100xf64>
    %view_0 = memref.view %0[%c2176][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %view_2 = memref.view %0[%c46976][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %cast = memref.cast %reinterpret_cast_1 : memref<56x100xf64> to memref<?x100xf64, strided<[100, 1]>>
    scf.for %arg0 = %c0 to %c600 step %c100 {
      %subview_13 = memref.subview %1[0, %arg0] [1, 100] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 600>> to memref<1x100xf64, strided<[600, 1], offset: ?>>
      %subview_14 = memref.subview %subview_13[0, 0] [1, 100] [1, 1] : memref<1x100xf64, strided<[600, 1], offset: ?>> to memref<100xf64, strided<[1], offset: ?>>
      %subview_15 = memref.subview %reinterpret_cast[0, 0] [1, 100] [1, 1] : memref<1x100xf64> to memref<100xf64, strided<[1]>>
      %8 = dma.start_transfer from %subview_14 : memref<100xf64, strided<[1], offset: ?>> to %subview_15 : memref<100xf64, strided<[1]>>
      dma.wait_for_transfer %8
      quidditch_snitch.barrier
      %subview_16 = memref.subview %2[0, %arg0] [56, 100] [1, 1] : memref<161x600xf64, strided<[600, 1], offset: 2590800>> to memref<56x100xf64, strided<[600, 1], offset: ?>>
      %cast_17 = memref.cast %subview_16 : memref<56x100xf64, strided<[600, 1], offset: ?>> to memref<?x100xf64, strided<[600, 1], offset: ?>>
      %9 = dma.start_transfer from %cast_17 : memref<?x100xf64, strided<[600, 1], offset: ?>> to %cast : memref<?x100xf64, strided<[100, 1]>>
      %10 = scf.for %arg1 = %c56 to %c168 step %c56 iter_args(%arg2 = %9) -> (!dma.token) {
        %11 = affine.min affine_map<(d0) -> (161, d0 + 56)>(%arg1)
        %12 = affine.apply affine_map<(d0, d1) -> (d0 - d1)>(%11, %arg1)
        %subview_18 = memref.subview %2[%arg1, %arg0] [%12, 100] [1, 1] : memref<161x600xf64, strided<[600, 1], offset: 2590800>> to memref<?x100xf64, strided<[600, 1], offset: ?>>
        %13 = affine.apply affine_map<(d0) -> ((d0 floordiv 56) mod 2)>(%arg1)
        %14 = scf.index_switch %13 -> memref<56x100xf64> 
        case 0 {
          scf.yield %reinterpret_cast_1 : memref<56x100xf64>
        }
        default {
          scf.yield %reinterpret_cast_3 : memref<56x100xf64>
        }
        %subview_19 = memref.subview %14[0, 0] [%12, 100] [1, 1] : memref<56x100xf64> to memref<?x100xf64, strided<[100, 1]>>
        %15 = dma.start_transfer from %subview_18 : memref<?x100xf64, strided<[600, 1], offset: ?>> to %subview_19 : memref<?x100xf64, strided<[100, 1]>>
        dma.wait_for_transfer %arg2
        quidditch_snitch.barrier
        quidditch_snitch.barrier
        scf.yield %15 : !dma.token
      }
      dma.wait_for_transfer %10
      quidditch_snitch.barrier
      quidditch_snitch.barrier
    }
    %view_4 = memref.view %0[%c91776][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %subview = memref.subview %reinterpret_cast_5[0, 0] [1, 161] [1, 1] : memref<1x168xf64> to memref<1x161xf64, strided<[168, 1]>>
    %subview_6 = memref.subview %3[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[161, 1], offset: 2687400>> to memref<161xf64, strided<[1], offset: 2687400>>
    %subview_7 = memref.subview %subview[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[168, 1]>> to memref<161xf64, strided<[1]>>
    %5 = dma.start_transfer from %subview_6 : memref<161xf64, strided<[1], offset: 2687400>> to %subview_7 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %5
    quidditch_snitch.barrier
    %view_8 = memref.view %0[%c93120][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_9 = memref.reinterpret_cast %view_8 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %subview_10 = memref.subview %reinterpret_cast_9[0, 0] [1, 161] [1, 1] : memref<1x168xf64> to memref<1x161xf64, strided<[168, 1]>>
    %subview_11 = memref.subview %4[0, 0] [1, 161] [1, 1] : memref<1x161xf64> to memref<161xf64, strided<[1]>>
    %subview_12 = memref.subview %subview_10[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[168, 1]>> to memref<161xf64, strided<[1]>>
    %6 = dma.start_transfer from %subview_11 : memref<161xf64, strided<[1]>> to %subview_12 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %6
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %7 = dma.start_transfer from %subview_12 : memref<161xf64, strided<[1]>> to %subview_11 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %7
    quidditch_snitch.barrier
    return
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (convertToRISCV) erasing the kernel op and continuing on...

/home/hoppip/Quidditch/runtime/samples/grapeFruit/grapeFruit.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
"builtin.module"() ({
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64"}> ({
    %53 = "arith.constant"() <{value = 93120 : index}> : () -> index
    %54 = "arith.constant"() <{value = 91776 : index}> : () -> index
    %55 = "arith.constant"() <{value = 46976 : index}> : () -> index
    %56 = "arith.constant"() <{value = 2176 : index}> : () -> index
    %57 = "arith.constant"() <{value = 1344 : index}> : () -> index
    %58 = "arith.constant"() <{value = 0 : index}> : () -> index
    %59 = "arith.constant"() <{value = 21499200 : index}> : () -> index
    %60 = "arith.constant"() <{value = 20726400 : index}> : () -> index
    %61 = "arith.constant"() <{value = 4800 : index}> : () -> index
    %62 = "arith.constant"() <{value = 600 : index}> : () -> index
    %63 = "arith.constant"() <{value = 100 : index}> : () -> index
    %64 = "arith.constant"() <{value = 168 : index}> : () -> index
    %65 = "arith.constant"() <{value = 56 : index}> : () -> index
    %66 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %67 = "hal.interface.binding.subspan"(%61) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
    "memref.assume_alignment"(%67) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
    %68 = "hal.interface.binding.subspan"(%60) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    "memref.assume_alignment"(%68) <{alignment = 64 : i32}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>) -> ()
    %69 = "hal.interface.binding.subspan"(%59) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    "memref.assume_alignment"(%69) <{alignment = 64 : i32}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> ()
    %70 = "hal.interface.binding.subspan"(%58) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64>
    "memref.assume_alignment"(%70) <{alignment = 64 : i32}> : (memref<1x161xf64>) -> ()
    %71 = "memref.view"(%66, %58) : (memref<100000xi8>, index) -> memref<168xf64>
    %72 = "memref.reinterpret_cast"(%71) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %73 = "quidditch_snitch.compute_core_index"() : () -> index
    %74 = "affine.apply"(%73) <{map = affine_map<()[s0] -> (s0 * 21)>}> : (index) -> index
    %75 = "memref.subview"(%72, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    "quidditch_snitch.call_microkernel"(%75) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0:\0A    mv t0, a0\0A    fcvt.d.w ft3, zero\0A    li t1, 20\0A    scfgwi t1, 64                                # dm 0 dim 0 bound\0A    li t1, 8\0A    scfgwi t1, 192                               # dm 0 dim 0 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    scfgwi t0, 896                               # dm 0 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 20\0A    frep.o t0, 1, 0, 0\0A    fmv.d ft0, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %76 = "memref.view"(%66, %57) : (memref<100000xi8>, index) -> memref<100xf64>
    %77 = "memref.reinterpret_cast"(%76) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 100, 1>}> : (memref<100xf64>) -> memref<1x100xf64>
    %78 = "memref.view"(%66, %56) : (memref<100000xi8>, index) -> memref<5600xf64>
    %79 = "memref.reinterpret_cast"(%78) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %80 = "memref.view"(%66, %55) : (memref<100000xi8>, index) -> memref<5600xf64>
    %81 = "memref.reinterpret_cast"(%80) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %82 = "affine.apply"(%73) <{map = affine_map<()[s0] -> (s0 * 7)>}> : (index) -> index
    %83 = "memref.subview"(%72) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 112>, static_sizes = array<i64: 1, 56>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x56xf64, strided<[168, 1], offset: 112>>
    "scf.for"(%58, %62, %63) ({
    ^bb0(%arg6: index):
      "quidditch_snitch.barrier"() : () -> ()
      %96 = "scf.for"(%65, %64, %65, %79) ({
      ^bb0(%arg7: index, %arg8: memref<56x100xf64>):
        %99 = "affine.apply"(%arg7) <{map = affine_map<(d0) -> ((d0 floordiv 56) mod 2)>}> : (index) -> index
        %100 = "scf.index_switch"(%99) <{cases = array<i64: 0>}> ({
          "scf.yield"(%81) : (memref<56x100xf64>) -> ()
        }, {
          "scf.yield"(%79) : (memref<56x100xf64>) -> ()
        }) : (index) -> memref<56x100xf64>
        %101 = "affine.apply"(%arg7) <{map = affine_map<(d0) -> (d0 - 56)>}> : (index) -> index
        %102 = "memref.subview"(%72, %101) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 56>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x56xf64, strided<[168, 1], offset: ?>>
        "quidditch_snitch.barrier"() : () -> ()
        %103 = "memref.subview"(%arg8, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: 7, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<7x100xf64, strided<[100, 1], offset: ?>>
        %104 = "memref.subview"(%102, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 7>, static_strides = array<i64: 1, 1>}> : (memref<1x56xf64, strided<[168, 1], offset: ?>>, index) -> memref<1x7xf64, strided<[168, 1], offset: ?>>
        "quidditch_snitch.call_microkernel"(%77, %103, %104) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    li t3, 99\0A    scfgwi t3, 64                                # dm 0 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 192                               # dm 0 dim 0 stride\0A    li t3, 6\0A    scfgwi t3, 32                                # dm 0 repeat\0A    li t3, 6\0A    scfgwi t3, 65                                # dm 1 dim 0 bound\0A    li t3, 99\0A    scfgwi t3, 97                                # dm 1 dim 1 bound\0A    li t3, 800\0A    scfgwi t3, 193                               # dm 1 dim 0 stride\0A    li t3, -4792\0A    scfgwi t3, 225                               # dm 1 dim 1 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 801                               # dm 1 dim 1 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    mv t1, t0\0A    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)\0A    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)\0A    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)\0A    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)\0A    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)\0A    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)\0A    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)\0A    li t1, 99\0A    frep.o t1, 7, 0, 0\0A    fmadd.d ft9, ft0, ft1, ft9\0A    fmadd.d ft8, ft0, ft1, ft8\0A    fmadd.d ft7, ft0, ft1, ft7\0A    fmadd.d ft6, ft0, ft1, ft6\0A    fmadd.d ft5, ft0, ft1, ft5\0A    fmadd.d ft4, ft0, ft1, ft4\0A    fmadd.d ft3, ft0, ft1, ft3\0A    mv t1, t0\0A    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)\0A    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)\0A    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>) -> ()
        "quidditch_snitch.microkernel_fence"() : () -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "scf.yield"(%100) : (memref<56x100xf64>) -> ()
      }) : (index, index, index, memref<56x100xf64>) -> memref<56x100xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %97 = "memref.subview"(%96, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: 7, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<7x100xf64, strided<[100, 1], offset: ?>>
      %98 = "memref.subview"(%83, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 7>, static_strides = array<i64: 1, 1>}> : (memref<1x56xf64, strided<[168, 1], offset: 112>>, index) -> memref<1x7xf64, strided<[168, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%77, %97, %98) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    li t3, 99\0A    scfgwi t3, 64                                # dm 0 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 192                               # dm 0 dim 0 stride\0A    li t3, 6\0A    scfgwi t3, 32                                # dm 0 repeat\0A    li t3, 6\0A    scfgwi t3, 65                                # dm 1 dim 0 bound\0A    li t3, 99\0A    scfgwi t3, 97                                # dm 1 dim 1 bound\0A    li t3, 800\0A    scfgwi t3, 193                               # dm 1 dim 0 stride\0A    li t3, -4792\0A    scfgwi t3, 225                               # dm 1 dim 1 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 801                               # dm 1 dim 1 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    mv t1, t0\0A    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)\0A    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)\0A    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)\0A    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)\0A    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)\0A    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)\0A    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)\0A    li t1, 99\0A    frep.o t1, 7, 0, 0\0A    fmadd.d ft9, ft0, ft1, ft9\0A    fmadd.d ft8, ft0, ft1, ft8\0A    fmadd.d ft7, ft0, ft1, ft7\0A    fmadd.d ft6, ft0, ft1, ft6\0A    fmadd.d ft5, ft0, ft1, ft5\0A    fmadd.d ft4, ft0, ft1, ft4\0A    fmadd.d ft3, ft0, ft1, ft3\0A    mv t1, t0\0A    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)\0A    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)\0A    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    %84 = "memref.view"(%66, %54) : (memref<100000xi8>, index) -> memref<168xf64>
    %85 = "memref.reinterpret_cast"(%84) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %86 = "memref.view"(%66, %53) : (memref<100000xi8>, index) -> memref<168xf64>
    %87 = "memref.reinterpret_cast"(%86) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %88 = "memref.subview"(%85, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    %89 = "memref.subview"(%87, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    %90 = "arith.constant"() <{value = 1.000000e+00 : f64}> : () -> f64
    "linalg.generic"(%75, %88, %89) <{indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 2, 1>}> ({
    ^bb0(%arg3: f64, %arg4: f64, %arg5: f64):
      %91 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %92 = "arith.negf"(%91) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %93 = "math.exp"(%92) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %94 = "arith.addf"(%93, %90) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %95 = "arith.divf"(%90, %94) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      "linalg.yield"(%95) : (f64) -> ()
    }) : (memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.memref.microkernel"(%75, %88, %89) ({
    }) : (memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {quidditch_snitch.dma_specialization = @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma"}> ({
    %0 = "arith.constant"() <{value = 93120 : index}> : () -> index
    %1 = "arith.constant"() <{value = 91776 : index}> : () -> index
    %2 = "arith.constant"() <{value = 46976 : index}> : () -> index
    %3 = "arith.constant"() <{value = 2176 : index}> : () -> index
    %4 = "arith.constant"() <{value = 1344 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "arith.constant"() <{value = 21499200 : index}> : () -> index
    %7 = "arith.constant"() <{value = 20726400 : index}> : () -> index
    %8 = "arith.constant"() <{value = 4800 : index}> : () -> index
    %9 = "arith.constant"() <{value = 600 : index}> : () -> index
    %10 = "arith.constant"() <{value = 100 : index}> : () -> index
    %11 = "arith.constant"() <{value = 168 : index}> : () -> index
    %12 = "arith.constant"() <{value = 56 : index}> : () -> index
    %13 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %14 = "hal.interface.binding.subspan"(%8) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
    "memref.assume_alignment"(%14) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
    %15 = "hal.interface.binding.subspan"(%7) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    "memref.assume_alignment"(%15) <{alignment = 64 : i32}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>) -> ()
    %16 = "hal.interface.binding.subspan"(%6) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    "memref.assume_alignment"(%16) <{alignment = 64 : i32}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> ()
    %17 = "hal.interface.binding.subspan"(%5) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64>
    "memref.assume_alignment"(%17) <{alignment = 64 : i32}> : (memref<1x161xf64>) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %18 = "memref.view"(%13, %4) : (memref<100000xi8>, index) -> memref<100xf64>
    %19 = "memref.reinterpret_cast"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 100, 1>}> : (memref<100xf64>) -> memref<1x100xf64>
    %20 = "memref.view"(%13, %3) : (memref<100000xi8>, index) -> memref<5600xf64>
    %21 = "memref.reinterpret_cast"(%20) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %22 = "memref.view"(%13, %2) : (memref<100000xi8>, index) -> memref<5600xf64>
    %23 = "memref.reinterpret_cast"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %24 = "memref.cast"(%21) : (memref<56x100xf64>) -> memref<?x100xf64, strided<[100, 1]>>
    "scf.for"(%5, %9, %10) ({
    ^bb0(%arg0: index):
      %38 = "memref.subview"(%14, %arg0) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>, index) -> memref<1x100xf64, strided<[600, 1], offset: ?>>
      %39 = "memref.subview"(%38) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x100xf64, strided<[600, 1], offset: ?>>) -> memref<100xf64, strided<[1], offset: ?>>
      %40 = "memref.subview"(%19) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x100xf64>) -> memref<100xf64, strided<[1]>>
      %41 = "dma.start_transfer"(%39, %40) : (memref<100xf64, strided<[1], offset: ?>>, memref<100xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%41) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %42 = "memref.subview"(%15, %arg0) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 1, 1>}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>, index) -> memref<56x100xf64, strided<[600, 1], offset: ?>>
      %43 = "memref.cast"(%42) : (memref<56x100xf64, strided<[600, 1], offset: ?>>) -> memref<?x100xf64, strided<[600, 1], offset: ?>>
      %44 = "dma.start_transfer"(%43, %24) : (memref<?x100xf64, strided<[600, 1], offset: ?>>, memref<?x100xf64, strided<[100, 1]>>) -> !dma.token
      %45 = "scf.for"(%12, %11, %12, %44) ({
      ^bb0(%arg1: index, %arg2: !dma.token):
        %46 = "affine.min"(%arg1) <{map = affine_map<(d0) -> (161, d0 + 56)>}> : (index) -> index
        %47 = "affine.apply"(%46, %arg1) <{map = affine_map<(d0, d1) -> (d0 - d1)>}> : (index, index) -> index
        %48 = "memref.subview"(%15, %arg1, %arg0, %47) <{operandSegmentSizes = array<i32: 1, 2, 1, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: -9223372036854775808, 100>, static_strides = array<i64: 1, 1>}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>, index, index, index) -> memref<?x100xf64, strided<[600, 1], offset: ?>>
        %49 = "affine.apply"(%arg1) <{map = affine_map<(d0) -> ((d0 floordiv 56) mod 2)>}> : (index) -> index
        %50 = "scf.index_switch"(%49) <{cases = array<i64: 0>}> ({
          "scf.yield"(%23) : (memref<56x100xf64>) -> ()
        }, {
          "scf.yield"(%21) : (memref<56x100xf64>) -> ()
        }) : (index) -> memref<56x100xf64>
        %51 = "memref.subview"(%50, %47) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: -9223372036854775808, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<?x100xf64, strided<[100, 1]>>
        %52 = "dma.start_transfer"(%48, %51) : (memref<?x100xf64, strided<[600, 1], offset: ?>>, memref<?x100xf64, strided<[100, 1]>>) -> !dma.token
        "dma.wait_for_transfer"(%arg2) : (!dma.token) -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "scf.yield"(%52) : (!dma.token) -> ()
      }) : (index, index, index, !dma.token) -> !dma.token
      "dma.wait_for_transfer"(%45) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    %25 = "memref.view"(%13, %1) : (memref<100000xi8>, index) -> memref<168xf64>
    %26 = "memref.reinterpret_cast"(%25) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %27 = "memref.subview"(%26) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x161xf64, strided<[168, 1]>>
    %28 = "memref.subview"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> memref<161xf64, strided<[1], offset: 2687400>>
    %29 = "memref.subview"(%27) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[168, 1]>>) -> memref<161xf64, strided<[1]>>
    %30 = "dma.start_transfer"(%28, %29) : (memref<161xf64, strided<[1], offset: 2687400>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%30) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %31 = "memref.view"(%13, %0) : (memref<100000xi8>, index) -> memref<168xf64>
    %32 = "memref.reinterpret_cast"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %33 = "memref.subview"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x161xf64, strided<[168, 1]>>
    %34 = "memref.subview"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64>) -> memref<161xf64, strided<[1]>>
    %35 = "memref.subview"(%33) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[168, 1]>>) -> memref<161xf64, strided<[1]>>
    %36 = "dma.start_transfer"(%34, %35) : (memref<161xf64, strided<[1]>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%36) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %37 = "dma.start_transfer"(%35, %34) : (memref<161xf64, strided<[1]>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%37) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
}) : () -> ()
[33/41] Generating nsnet2/nsnet2_module.h, nsnet2/nsnet2.o, nsnet2/nsnet2.h, nsnet2/nsnet2_llvm.h, nsnet2/nsnet2_llvm.o
FAILED: samples/nsnet2/nsnet2/nsnet2_module.h samples/nsnet2/nsnet2/nsnet2.o samples/nsnet2/nsnet2/nsnet2.h samples/nsnet2/nsnet2/nsnet2_llvm.h samples/nsnet2/nsnet2/nsnet2_llvm.o /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2_module.h /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2.o /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2.h /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2_llvm.h /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2_llvm.o 
cd /home/hoppip/Quidditch/build/runtime/samples/nsnet2 && /home/hoppip/Quidditch/build/codegen/iree-configuration/iree/tools/iree-compile --iree-vm-bytecode-module-strip-source-map=true --iree-vm-emit-polyglot-zip=false --iree-input-type=auto --iree-input-demote-f64-to-f32=0 --iree-hal-target-backends=quidditch --iree-quidditch-static-library-output-path=/home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2.o --iree-quidditch-xdsl-opt-path=/home/hoppip/Quidditch/venv/bin/xdsl-opt --iree-quidditch-toolchain-root=/home/hoppip/Quidditch/toolchain --iree-hal-target-backends=llvm-cpu --iree-llvmcpu-debug-symbols=true --iree-llvmcpu-target-triple=riscv32-unknown-elf --iree-llvmcpu-target-cpu=generic-rv32 --iree-llvmcpu-target-cpu-features=+m,+f,+d,+zfh --iree-llvmcpu-target-abi=ilp32d --iree-llvmcpu-target-float-abi=hard --iree-llvmcpu-link-embedded=false --iree-llvmcpu-link-static --iree-llvmcpu-number-of-threads=8 --iree-llvmcpu-static-library-output-path=/home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2_llvm.o --output-format=vm-c --iree-vm-target-index-bits=32 /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2.mlirbc -o /home/hoppip/Quidditch/build/runtime/samples/nsnet2/nsnet2/nsnet2_module.h
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:96:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:96:0: note: see current operation: %11 = dma.start_transfer from %subview_18 : memref<1x100xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %8 = dma.start_transfer from %3 : memref<1x600xf64, strided<[600, 1], offset: 2229600>> to %cast_11 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %10 = dma.start_transfer from %4 : memref<1x600xf64> to %cast_16 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:98:0: note: see current operation: %12 = dma.start_transfer from %reinterpret_cast_15 : memref<1x600xf64> to %4 : memref<1x600xf64>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %23 = dma.start_transfer from %subview_15 : memref<1x25xf64, strided<[400, 1], offset: ?>> to %cast : memref<1x25xf64, strided<[25, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %20 = dma.start_transfer from %16 : memref<1x1200xf64, strided<[1200, 1], offset: ?>> to %cast_8 : memref<1x1200xf64, strided<[1200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %22 = dma.start_transfer from %17 : memref<1x1200xf64, strided<[1200, 1], offset: ?>> to %cast_13 : memref<1x1200xf64, strided<[1200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:19:0: note: see current operation: %24 = dma.start_transfer from %reinterpret_cast_12 : memref<1x1200xf64> to %17 : memref<1x1200xf64, strided<[1200, 1], offset: ?>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:110:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:110:0: note: see current operation: %11 = dma.start_transfer from %subview_18 : memref<1x100xf64, strided<[600, 1], offset: ?>> to %cast : memref<1x100xf64, strided<[100, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %8 = dma.start_transfer from %3 : memref<1x161xf64, strided<[161, 1], offset: 2687400>> to %subview_11 : memref<1x161xf64, strided<[168, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %10 = dma.start_transfer from %4 : memref<1x161xf64> to %subview_16 : memref<1x161xf64, strided<[168, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: %12 = dma.start_transfer from %subview_16 : memref<1x161xf64, strided<[168, 1]>> to %4 : memref<1x161xf64>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: Failed to translate kernel with xDSL
/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
quidditch_snitch.memref.microkernel(<<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>) : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>> {
^bb0(%arg0: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg1: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg2: memref<1x21xf64, strided<[168, 1], offset: ?>>):
  %cst = arith.constant 1.000000e+00 : f64
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) outs(%arg2 : memref<1x21xf64, strided<[168, 1], offset: ?>>) {
  ^bb0(%in: f64, %in_0: f64, %out: f64):
    %0 = arith.addf %in, %in_0 : f64
    %1 = arith.negf %0 : f64
    %2 = math.exp %1 : f64
    %3 = arith.addf %2, %cst : f64
    %4 = arith.divf %cst, %3 : f64
    linalg.yield %4 : f64
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: stderr:
Traceback (most recent call last):
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 534, in parse_chunk
    return self.available_frontends[file_extension](chunk)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 520, in parse_mlir
    ).parse_module(not self.args.no_implicit_module)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 127, in parse_module
    if (parsed_op := self.parse_optional_operation()) is not None:
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/func.py", line 138, in parse
    ) = parse_func_op_like(
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/utils.py", line 239, in parse_func_op_like
    region = parser.parse_optional_region(entry_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 539, in parse_optional_region
    self._parse_block_body(entry_block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/linalg.py", line 354, in parse
    body = parser.parse_region()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 594, in parse_region
    region = self.parse_optional_region(arguments)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 558, in parse_optional_region
    block = self._parse_block()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 247, in _parse_block
    self._parse_block_body(block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/ir/core.py", line 869, in parse
    parser.raise_error(f"Operation {cls.name} does not have a custom format.")
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/base_parser.py", line 107, in raise_error
    raise ParseError(at_position, msg)
xdsl.utils.exceptions.ParseError: stdin:7:18
    %2 = math.exp %1 : f64
                  ^^
                  Operation math.exp does not have a custom format.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hoppip/Quidditch/venv/bin/xdsl-opt", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/xdsl_opt.py", line 5, in main
    xDSLOptMain().run()
  File "/home/hoppip/Quidditch/xdsl/xdsl/xdsl_opt_main.py", line 71, in run
    module = self.parse_chunk(chunk, file_extension, offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 541, in parse_chunk
    raise Exception("Failed to parse:\n" + e.with_context()) from e
Exception: Failed to parse:
stdin:7:18
    %2 = math.exp %1 : f64
                  ^^
                  Operation math.exp does not have a custom format.


<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (convertToRISCV) convert to RISCV assembly failed

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
module {
  func.func @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c93120 = arith.constant 93120 : index
    %c91776 = arith.constant 91776 : index
    %c46976 = arith.constant 46976 : index
    %c2176 = arith.constant 2176 : index
    %c1344 = arith.constant 1344 : index
    %c0 = arith.constant 0 : index
    %c21499200 = arith.constant 21499200 : index
    %c20726400 = arith.constant 20726400 : index
    %c4800 = arith.constant 4800 : index
    %c600 = arith.constant 600 : index
    %c100 = arith.constant 100 : index
    %c168 = arith.constant 168 : index
    %c56 = arith.constant 56 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c4800) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %1, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20726400) flags(ReadOnly) : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    memref.assume_alignment %2, 64 : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c21499200) flags(ReadOnly) : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    memref.assume_alignment %3, 64 : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x161xf64>
    memref.assume_alignment %4, 64 : memref<1x161xf64>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %5 = quidditch_snitch.compute_core_index
    %6 = affine.apply affine_map<()[s0] -> (s0 * 21)>()[%5]
    %subview = memref.subview %reinterpret_cast[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0"(%subview) : memref<1x21xf64, strided<[168, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0"
      ".p2align 2"
      "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0:"
      "    mv t0, a0"
      "    fcvt.d.w ft3, zero"
      "    li t1, 20"
      "    scfgwi t1, 64                                # dm 0 dim 0 bound"
      "    li t1, 8"
      "    scfgwi t1, 192                               # dm 0 dim 0 stride"
      "    scfgwi zero, 32                              # dm 0 repeat"
      "    scfgwi t0, 896                               # dm 0 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 20"
      "    frep.o t0, 1, 0, 0"
      "    fmv.d ft0, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c1344][] : memref<100000xi8> to memref<100xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [1, 100], strides: [100, 1] : memref<100xf64> to memref<1x100xf64>
    %view_2 = memref.view %0[%c2176][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %view_4 = memref.view %0[%c46976][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %7 = affine.apply affine_map<()[s0] -> (s0 * 7)>()[%5]
    %subview_6 = memref.subview %reinterpret_cast[0, 112] [1, 56] [1, 1] : memref<1x168xf64> to memref<1x56xf64, strided<[168, 1], offset: 112>>
    scf.for %arg0 = %c0 to %c600 step %c100 {
      quidditch_snitch.barrier
      %8 = scf.for %arg1 = %c56 to %c168 step %c56 iter_args(%arg2 = %reinterpret_cast_3) -> (memref<56x100xf64>) {
        %9 = affine.apply affine_map<(d0) -> ((d0 floordiv 56) mod 2)>(%arg1)
        %10 = scf.index_switch %9 -> memref<56x100xf64> 
        case 0 {
          scf.yield %reinterpret_cast_3 : memref<56x100xf64>
        }
        default {
          scf.yield %reinterpret_cast_5 : memref<56x100xf64>
        }
        %11 = affine.apply affine_map<(d0) -> (d0 - 56)>(%arg1)
        %subview_15 = memref.subview %reinterpret_cast[0, %11] [1, 56] [1, 1] : memref<1x168xf64> to memref<1x56xf64, strided<[168, 1], offset: ?>>
        quidditch_snitch.barrier
        %subview_16 = memref.subview %arg2[%7, 0] [7, 100] [1, 1] : memref<56x100xf64> to memref<7x100xf64, strided<[100, 1], offset: ?>>
        %subview_17 = memref.subview %subview_15[0, %7] [1, 7] [1, 1] : memref<1x56xf64, strided<[168, 1], offset: ?>> to memref<1x7xf64, strided<[168, 1], offset: ?>>
        quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1"(%reinterpret_cast_1, %subview_16, %subview_17) : memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>[{
          ".text"
          ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1"
          ".p2align 2"
          "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1:"
          "    mv t2, a0"
          "    mv t1, a1"
          "    mv t0, a2"
          "    li t3, 99"
          "    scfgwi t3, 64                                # dm 0 dim 0 bound"
          "    li t3, 8"
          "    scfgwi t3, 192                               # dm 0 dim 0 stride"
          "    li t3, 6"
          "    scfgwi t3, 32                                # dm 0 repeat"
          "    li t3, 6"
          "    scfgwi t3, 65                                # dm 1 dim 0 bound"
          "    li t3, 99"
          "    scfgwi t3, 97                                # dm 1 dim 1 bound"
          "    li t3, 800"
          "    scfgwi t3, 193                               # dm 1 dim 0 stride"
          "    li t3, -4792"
          "    scfgwi t3, 225                               # dm 1 dim 1 stride"
          "    scfgwi zero, 33                              # dm 1 repeat"
          "    scfgwi t2, 768                               # dm 0 dim 0 source"
          "    scfgwi t1, 801                               # dm 1 dim 1 source"
          "    csrrsi zero, 1984, 1                         # SSR enable"
          "    mv t1, t0"
          "    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)"
          "    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)"
          "    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)"
          "    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)"
          "    li t1, 99"
          "    frep.o t1, 7, 0, 0"
          "    fmadd.d ft9, ft0, ft1, ft9"
          "    fmadd.d ft8, ft0, ft1, ft8"
          "    fmadd.d ft7, ft0, ft1, ft7"
          "    fmadd.d ft6, ft0, ft1, ft6"
          "    fmadd.d ft5, ft0, ft1, ft5"
          "    fmadd.d ft4, ft0, ft1, ft4"
          "    fmadd.d ft3, ft0, ft1, ft3"
          "    mv t1, t0"
          "    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)"
          "    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)"
          "    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)"
          "    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)"
          "    csrrci zero, 1984, 1                         # SSR disable"
          "    ret"
          ""
        }]
        quidditch_snitch.microkernel_fence
        quidditch_snitch.barrier
        scf.yield %10 : memref<56x100xf64>
      }
      quidditch_snitch.barrier
      %subview_13 = memref.subview %8[%7, 0] [7, 100] [1, 1] : memref<56x100xf64> to memref<7x100xf64, strided<[100, 1], offset: ?>>
      %subview_14 = memref.subview %subview_6[0, %7] [1, 7] [1, 1] : memref<1x56xf64, strided<[168, 1], offset: 112>> to memref<1x7xf64, strided<[168, 1], offset: ?>>
      quidditch_snitch.call_microkernel "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2"(%reinterpret_cast_1, %subview_13, %subview_14) : memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>[{
        ".text"
        ".globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2"
        ".p2align 2"
        "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2:"
        "    mv t2, a0"
        "    mv t1, a1"
        "    mv t0, a2"
        "    li t3, 99"
        "    scfgwi t3, 64                                # dm 0 dim 0 bound"
        "    li t3, 8"
        "    scfgwi t3, 192                               # dm 0 dim 0 stride"
        "    li t3, 6"
        "    scfgwi t3, 32                                # dm 0 repeat"
        "    li t3, 6"
        "    scfgwi t3, 65                                # dm 1 dim 0 bound"
        "    li t3, 99"
        "    scfgwi t3, 97                                # dm 1 dim 1 bound"
        "    li t3, 800"
        "    scfgwi t3, 193                               # dm 1 dim 0 stride"
        "    li t3, -4792"
        "    scfgwi t3, 225                               # dm 1 dim 1 stride"
        "    scfgwi zero, 33                              # dm 1 repeat"
        "    scfgwi t2, 768                               # dm 0 dim 0 source"
        "    scfgwi t1, 801                               # dm 1 dim 1 source"
        "    csrrsi zero, 1984, 1                         # SSR enable"
        "    mv t1, t0"
        "    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)"
        "    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)"
        "    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)"
        "    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)"
        "    li t1, 99"
        "    frep.o t1, 7, 0, 0"
        "    fmadd.d ft9, ft0, ft1, ft9"
        "    fmadd.d ft8, ft0, ft1, ft8"
        "    fmadd.d ft7, ft0, ft1, ft7"
        "    fmadd.d ft6, ft0, ft1, ft6"
        "    fmadd.d ft5, ft0, ft1, ft5"
        "    fmadd.d ft4, ft0, ft1, ft4"
        "    fmadd.d ft3, ft0, ft1, ft3"
        "    mv t1, t0"
        "    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)"
        "    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)"
        "    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)"
        "    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)"
        "    csrrci zero, 1984, 1                         # SSR disable"
        "    ret"
        ""
      }]
      quidditch_snitch.microkernel_fence
      quidditch_snitch.barrier
    }
    %view_7 = memref.view %0[%c91776][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_8 = memref.reinterpret_cast %view_7 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    quidditch_snitch.barrier
    %view_9 = memref.view %0[%c93120][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_10 = memref.reinterpret_cast %view_9 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    quidditch_snitch.barrier
    %subview_11 = memref.subview %reinterpret_cast_8[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    %subview_12 = memref.subview %reinterpret_cast_10[0, %6] [1, 21] [1, 1] : memref<1x168xf64> to memref<1x21xf64, strided<[168, 1], offset: ?>>
    quidditch_snitch.memref.microkernel(%subview, %subview_11, %subview_12) : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>> {
    ^bb0(%arg0: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg1: memref<1x21xf64, strided<[168, 1], offset: ?>>, %arg2: memref<1x21xf64, strided<[168, 1], offset: ?>>):
      %cst = arith.constant 1.000000e+00 : f64
      linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) outs(%arg2 : memref<1x21xf64, strided<[168, 1], offset: ?>>) {
      ^bb0(%in: f64, %in_13: f64, %out: f64):
        %8 = arith.addf %in, %in_13 : f64
        %9 = arith.negf %8 : f64
        %10 = math.exp %9 : f64
        %11 = arith.addf %10, %cst : f64
        %12 = arith.divf %cst, %11 : f64
        linalg.yield %12 : f64
      }
    }
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c93120 = arith.constant 93120 : index
    %c91776 = arith.constant 91776 : index
    %c46976 = arith.constant 46976 : index
    %c2176 = arith.constant 2176 : index
    %c1344 = arith.constant 1344 : index
    %c0 = arith.constant 0 : index
    %c21499200 = arith.constant 21499200 : index
    %c20726400 = arith.constant 20726400 : index
    %c4800 = arith.constant 4800 : index
    %c600 = arith.constant 600 : index
    %c100 = arith.constant 100 : index
    %c168 = arith.constant 168 : index
    %c56 = arith.constant 56 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c4800) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %1, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20726400) flags(ReadOnly) : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    memref.assume_alignment %2, 64 : memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c21499200) flags(ReadOnly) : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    memref.assume_alignment %3, 64 : memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x161xf64>
    memref.assume_alignment %4, 64 : memref<1x161xf64>
    quidditch_snitch.barrier
    %view = memref.view %0[%c1344][] : memref<100000xi8> to memref<100xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 100], strides: [100, 1] : memref<100xf64> to memref<1x100xf64>
    %view_0 = memref.view %0[%c2176][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %view_2 = memref.view %0[%c46976][] : memref<100000xi8> to memref<5600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [56, 100], strides: [100, 1] : memref<5600xf64> to memref<56x100xf64>
    %cast = memref.cast %reinterpret_cast_1 : memref<56x100xf64> to memref<?x100xf64, strided<[100, 1]>>
    scf.for %arg0 = %c0 to %c600 step %c100 {
      %subview_13 = memref.subview %1[0, %arg0] [1, 100] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 600>> to memref<1x100xf64, strided<[600, 1], offset: ?>>
      %subview_14 = memref.subview %subview_13[0, 0] [1, 100] [1, 1] : memref<1x100xf64, strided<[600, 1], offset: ?>> to memref<100xf64, strided<[1], offset: ?>>
      %subview_15 = memref.subview %reinterpret_cast[0, 0] [1, 100] [1, 1] : memref<1x100xf64> to memref<100xf64, strided<[1]>>
      %8 = dma.start_transfer from %subview_14 : memref<100xf64, strided<[1], offset: ?>> to %subview_15 : memref<100xf64, strided<[1]>>
      dma.wait_for_transfer %8
      quidditch_snitch.barrier
      %subview_16 = memref.subview %2[0, %arg0] [56, 100] [1, 1] : memref<161x600xf64, strided<[600, 1], offset: 2590800>> to memref<56x100xf64, strided<[600, 1], offset: ?>>
      %cast_17 = memref.cast %subview_16 : memref<56x100xf64, strided<[600, 1], offset: ?>> to memref<?x100xf64, strided<[600, 1], offset: ?>>
      %9 = dma.start_transfer from %cast_17 : memref<?x100xf64, strided<[600, 1], offset: ?>> to %cast : memref<?x100xf64, strided<[100, 1]>>
      %10 = scf.for %arg1 = %c56 to %c168 step %c56 iter_args(%arg2 = %9) -> (!dma.token) {
        %11 = affine.min affine_map<(d0) -> (161, d0 + 56)>(%arg1)
        %12 = affine.apply affine_map<(d0, d1) -> (d0 - d1)>(%11, %arg1)
        %subview_18 = memref.subview %2[%arg1, %arg0] [%12, 100] [1, 1] : memref<161x600xf64, strided<[600, 1], offset: 2590800>> to memref<?x100xf64, strided<[600, 1], offset: ?>>
        %13 = affine.apply affine_map<(d0) -> ((d0 floordiv 56) mod 2)>(%arg1)
        %14 = scf.index_switch %13 -> memref<56x100xf64> 
        case 0 {
          scf.yield %reinterpret_cast_1 : memref<56x100xf64>
        }
        default {
          scf.yield %reinterpret_cast_3 : memref<56x100xf64>
        }
        %subview_19 = memref.subview %14[0, 0] [%12, 100] [1, 1] : memref<56x100xf64> to memref<?x100xf64, strided<[100, 1]>>
        %15 = dma.start_transfer from %subview_18 : memref<?x100xf64, strided<[600, 1], offset: ?>> to %subview_19 : memref<?x100xf64, strided<[100, 1]>>
        dma.wait_for_transfer %arg2
        quidditch_snitch.barrier
        quidditch_snitch.barrier
        scf.yield %15 : !dma.token
      }
      dma.wait_for_transfer %10
      quidditch_snitch.barrier
      quidditch_snitch.barrier
    }
    %view_4 = memref.view %0[%c91776][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %subview = memref.subview %reinterpret_cast_5[0, 0] [1, 161] [1, 1] : memref<1x168xf64> to memref<1x161xf64, strided<[168, 1]>>
    %subview_6 = memref.subview %3[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[161, 1], offset: 2687400>> to memref<161xf64, strided<[1], offset: 2687400>>
    %subview_7 = memref.subview %subview[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[168, 1]>> to memref<161xf64, strided<[1]>>
    %5 = dma.start_transfer from %subview_6 : memref<161xf64, strided<[1], offset: 2687400>> to %subview_7 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %5
    quidditch_snitch.barrier
    %view_8 = memref.view %0[%c93120][] : memref<100000xi8> to memref<168xf64>
    %reinterpret_cast_9 = memref.reinterpret_cast %view_8 to offset: [0], sizes: [1, 168], strides: [168, 1] : memref<168xf64> to memref<1x168xf64>
    %subview_10 = memref.subview %reinterpret_cast_9[0, 0] [1, 161] [1, 1] : memref<1x168xf64> to memref<1x161xf64, strided<[168, 1]>>
    %subview_11 = memref.subview %4[0, 0] [1, 161] [1, 1] : memref<1x161xf64> to memref<161xf64, strided<[1]>>
    %subview_12 = memref.subview %subview_10[0, 0] [1, 161] [1, 1] : memref<1x161xf64, strided<[168, 1]>> to memref<161xf64, strided<[1]>>
    %6 = dma.start_transfer from %subview_11 : memref<161xf64, strided<[1]>> to %subview_12 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %6
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %7 = dma.start_transfer from %subview_12 : memref<161xf64, strided<[1]>> to %subview_11 : memref<161xf64, strided<[1]>>
    dma.wait_for_transfer %7
    quidditch_snitch.barrier
    return
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: warning: 
RADDISH: (convertToRISCV) erasing the kernel op and continuing on...

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:112:0: note: see current operation: 
"builtin.module"() ({
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64"}> ({
    %53 = "arith.constant"() <{value = 93120 : index}> : () -> index
    %54 = "arith.constant"() <{value = 91776 : index}> : () -> index
    %55 = "arith.constant"() <{value = 46976 : index}> : () -> index
    %56 = "arith.constant"() <{value = 2176 : index}> : () -> index
    %57 = "arith.constant"() <{value = 1344 : index}> : () -> index
    %58 = "arith.constant"() <{value = 0 : index}> : () -> index
    %59 = "arith.constant"() <{value = 21499200 : index}> : () -> index
    %60 = "arith.constant"() <{value = 20726400 : index}> : () -> index
    %61 = "arith.constant"() <{value = 4800 : index}> : () -> index
    %62 = "arith.constant"() <{value = 600 : index}> : () -> index
    %63 = "arith.constant"() <{value = 100 : index}> : () -> index
    %64 = "arith.constant"() <{value = 168 : index}> : () -> index
    %65 = "arith.constant"() <{value = 56 : index}> : () -> index
    %66 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %67 = "hal.interface.binding.subspan"(%61) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
    "memref.assume_alignment"(%67) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
    %68 = "hal.interface.binding.subspan"(%60) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    "memref.assume_alignment"(%68) <{alignment = 64 : i32}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>) -> ()
    %69 = "hal.interface.binding.subspan"(%59) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    "memref.assume_alignment"(%69) <{alignment = 64 : i32}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> ()
    %70 = "hal.interface.binding.subspan"(%58) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64>
    "memref.assume_alignment"(%70) <{alignment = 64 : i32}> : (memref<1x161xf64>) -> ()
    %71 = "memref.view"(%66, %58) : (memref<100000xi8>, index) -> memref<168xf64>
    %72 = "memref.reinterpret_cast"(%71) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %73 = "quidditch_snitch.compute_core_index"() : () -> index
    %74 = "affine.apply"(%73) <{map = affine_map<()[s0] -> (s0 * 21)>}> : (index) -> index
    %75 = "memref.subview"(%72, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    "quidditch_snitch.call_microkernel"(%75) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel0:\0A    mv t0, a0\0A    fcvt.d.w ft3, zero\0A    li t1, 20\0A    scfgwi t1, 64                                # dm 0 dim 0 bound\0A    li t1, 8\0A    scfgwi t1, 192                               # dm 0 dim 0 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    scfgwi t0, 896                               # dm 0 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 20\0A    frep.o t0, 1, 0, 0\0A    fmv.d ft0, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %76 = "memref.view"(%66, %57) : (memref<100000xi8>, index) -> memref<100xf64>
    %77 = "memref.reinterpret_cast"(%76) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 100, 1>}> : (memref<100xf64>) -> memref<1x100xf64>
    %78 = "memref.view"(%66, %56) : (memref<100000xi8>, index) -> memref<5600xf64>
    %79 = "memref.reinterpret_cast"(%78) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %80 = "memref.view"(%66, %55) : (memref<100000xi8>, index) -> memref<5600xf64>
    %81 = "memref.reinterpret_cast"(%80) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %82 = "affine.apply"(%73) <{map = affine_map<()[s0] -> (s0 * 7)>}> : (index) -> index
    %83 = "memref.subview"(%72) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 112>, static_sizes = array<i64: 1, 56>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x56xf64, strided<[168, 1], offset: 112>>
    "scf.for"(%58, %62, %63) ({
    ^bb0(%arg6: index):
      "quidditch_snitch.barrier"() : () -> ()
      %96 = "scf.for"(%65, %64, %65, %79) ({
      ^bb0(%arg7: index, %arg8: memref<56x100xf64>):
        %99 = "affine.apply"(%arg7) <{map = affine_map<(d0) -> ((d0 floordiv 56) mod 2)>}> : (index) -> index
        %100 = "scf.index_switch"(%99) <{cases = array<i64: 0>}> ({
          "scf.yield"(%81) : (memref<56x100xf64>) -> ()
        }, {
          "scf.yield"(%79) : (memref<56x100xf64>) -> ()
        }) : (index) -> memref<56x100xf64>
        %101 = "affine.apply"(%arg7) <{map = affine_map<(d0) -> (d0 - 56)>}> : (index) -> index
        %102 = "memref.subview"(%72, %101) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 56>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x56xf64, strided<[168, 1], offset: ?>>
        "quidditch_snitch.barrier"() : () -> ()
        %103 = "memref.subview"(%arg8, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: 7, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<7x100xf64, strided<[100, 1], offset: ?>>
        %104 = "memref.subview"(%102, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 7>, static_strides = array<i64: 1, 1>}> : (memref<1x56xf64, strided<[168, 1], offset: ?>>, index) -> memref<1x7xf64, strided<[168, 1], offset: ?>>
        "quidditch_snitch.call_microkernel"(%77, %103, %104) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel1:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    li t3, 99\0A    scfgwi t3, 64                                # dm 0 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 192                               # dm 0 dim 0 stride\0A    li t3, 6\0A    scfgwi t3, 32                                # dm 0 repeat\0A    li t3, 6\0A    scfgwi t3, 65                                # dm 1 dim 0 bound\0A    li t3, 99\0A    scfgwi t3, 97                                # dm 1 dim 1 bound\0A    li t3, 800\0A    scfgwi t3, 193                               # dm 1 dim 0 stride\0A    li t3, -4792\0A    scfgwi t3, 225                               # dm 1 dim 1 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 801                               # dm 1 dim 1 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    mv t1, t0\0A    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)\0A    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)\0A    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)\0A    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)\0A    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)\0A    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)\0A    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)\0A    li t1, 99\0A    frep.o t1, 7, 0, 0\0A    fmadd.d ft9, ft0, ft1, ft9\0A    fmadd.d ft8, ft0, ft1, ft8\0A    fmadd.d ft7, ft0, ft1, ft7\0A    fmadd.d ft6, ft0, ft1, ft6\0A    fmadd.d ft5, ft0, ft1, ft5\0A    fmadd.d ft4, ft0, ft1, ft4\0A    fmadd.d ft3, ft0, ft1, ft3\0A    mv t1, t0\0A    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)\0A    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)\0A    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>) -> ()
        "quidditch_snitch.microkernel_fence"() : () -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "scf.yield"(%100) : (memref<56x100xf64>) -> ()
      }) : (index, index, index, memref<56x100xf64>) -> memref<56x100xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %97 = "memref.subview"(%96, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: 7, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<7x100xf64, strided<[100, 1], offset: ?>>
      %98 = "memref.subview"(%83, %82) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 7>, static_strides = array<i64: 1, 1>}> : (memref<1x56xf64, strided<[168, 1], offset: 112>>, index) -> memref<1x7xf64, strided<[168, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%77, %97, %98) <{name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2", riscv_assembly = ".text\0A.globl main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2\0A.p2align 2\0Amain$async_dispatch_9_matmul_transpose_b_1x161x600_f64$xdsl_kernel2:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    li t3, 99\0A    scfgwi t3, 64                                # dm 0 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 192                               # dm 0 dim 0 stride\0A    li t3, 6\0A    scfgwi t3, 32                                # dm 0 repeat\0A    li t3, 6\0A    scfgwi t3, 65                                # dm 1 dim 0 bound\0A    li t3, 99\0A    scfgwi t3, 97                                # dm 1 dim 1 bound\0A    li t3, 800\0A    scfgwi t3, 193                               # dm 1 dim 0 stride\0A    li t3, -4792\0A    scfgwi t3, 225                               # dm 1 dim 1 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 801                               # dm 1 dim 1 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    mv t1, t0\0A    fld ft9, 0(t1)                               # load double from memref of shape (1, 7)\0A    fld ft8, 8(t0)                               # load double from memref of shape (1, 7)\0A    fld ft7, 16(t0)                              # load double from memref of shape (1, 7)\0A    fld ft6, 24(t0)                              # load double from memref of shape (1, 7)\0A    fld ft5, 32(t0)                              # load double from memref of shape (1, 7)\0A    fld ft4, 40(t0)                              # load double from memref of shape (1, 7)\0A    fld ft3, 48(t0)                              # load double from memref of shape (1, 7)\0A    li t1, 99\0A    frep.o t1, 7, 0, 0\0A    fmadd.d ft9, ft0, ft1, ft9\0A    fmadd.d ft8, ft0, ft1, ft8\0A    fmadd.d ft7, ft0, ft1, ft7\0A    fmadd.d ft6, ft0, ft1, ft6\0A    fmadd.d ft5, ft0, ft1, ft5\0A    fmadd.d ft4, ft0, ft1, ft4\0A    fmadd.d ft3, ft0, ft1, ft3\0A    mv t1, t0\0A    fsd ft9, 0(t1)                               # store double value to memref of shape (1, 7)\0A    fsd ft8, 8(t0)                               # store double value to memref of shape (1, 7)\0A    fsd ft7, 16(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft6, 24(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft5, 32(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft4, 40(t0)                              # store double value to memref of shape (1, 7)\0A    fsd ft3, 48(t0)                              # store double value to memref of shape (1, 7)\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x100xf64>, memref<7x100xf64, strided<[100, 1], offset: ?>>, memref<1x7xf64, strided<[168, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    %84 = "memref.view"(%66, %54) : (memref<100000xi8>, index) -> memref<168xf64>
    %85 = "memref.reinterpret_cast"(%84) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %86 = "memref.view"(%66, %53) : (memref<100000xi8>, index) -> memref<168xf64>
    %87 = "memref.reinterpret_cast"(%86) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %88 = "memref.subview"(%85, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    %89 = "memref.subview"(%87, %74) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 21>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>, index) -> memref<1x21xf64, strided<[168, 1], offset: ?>>
    %90 = "arith.constant"() <{value = 1.000000e+00 : f64}> : () -> f64
    "linalg.generic"(%75, %88, %89) <{indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 2, 1>}> ({
    ^bb0(%arg3: f64, %arg4: f64, %arg5: f64):
      %91 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %92 = "arith.negf"(%91) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %93 = "math.exp"(%92) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %94 = "arith.addf"(%93, %90) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %95 = "arith.divf"(%90, %94) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      "linalg.yield"(%95) : (f64) -> ()
    }) : (memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.memref.microkernel"(%75, %88, %89) ({
    }) : (memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>, memref<1x21xf64, strided<[168, 1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {quidditch_snitch.dma_specialization = @main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_9_matmul_transpose_b_1x161x600_f64$dma"}> ({
    %0 = "arith.constant"() <{value = 93120 : index}> : () -> index
    %1 = "arith.constant"() <{value = 91776 : index}> : () -> index
    %2 = "arith.constant"() <{value = 46976 : index}> : () -> index
    %3 = "arith.constant"() <{value = 2176 : index}> : () -> index
    %4 = "arith.constant"() <{value = 1344 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "arith.constant"() <{value = 21499200 : index}> : () -> index
    %7 = "arith.constant"() <{value = 20726400 : index}> : () -> index
    %8 = "arith.constant"() <{value = 4800 : index}> : () -> index
    %9 = "arith.constant"() <{value = 600 : index}> : () -> index
    %10 = "arith.constant"() <{value = 100 : index}> : () -> index
    %11 = "arith.constant"() <{value = 168 : index}> : () -> index
    %12 = "arith.constant"() <{value = 56 : index}> : () -> index
    %13 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %14 = "hal.interface.binding.subspan"(%8) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
    "memref.assume_alignment"(%14) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
    %15 = "hal.interface.binding.subspan"(%7) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<161x600xf64, strided<[600, 1], offset: 2590800>>
    "memref.assume_alignment"(%15) <{alignment = 64 : i32}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>) -> ()
    %16 = "hal.interface.binding.subspan"(%6) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64, strided<[161, 1], offset: 2687400>>
    "memref.assume_alignment"(%16) <{alignment = 64 : i32}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> ()
    %17 = "hal.interface.binding.subspan"(%5) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x161xf64>
    "memref.assume_alignment"(%17) <{alignment = 64 : i32}> : (memref<1x161xf64>) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %18 = "memref.view"(%13, %4) : (memref<100000xi8>, index) -> memref<100xf64>
    %19 = "memref.reinterpret_cast"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 100, 1>}> : (memref<100xf64>) -> memref<1x100xf64>
    %20 = "memref.view"(%13, %3) : (memref<100000xi8>, index) -> memref<5600xf64>
    %21 = "memref.reinterpret_cast"(%20) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %22 = "memref.view"(%13, %2) : (memref<100000xi8>, index) -> memref<5600xf64>
    %23 = "memref.reinterpret_cast"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 100, 1>}> : (memref<5600xf64>) -> memref<56x100xf64>
    %24 = "memref.cast"(%21) : (memref<56x100xf64>) -> memref<?x100xf64, strided<[100, 1]>>
    "scf.for"(%5, %9, %10) ({
    ^bb0(%arg0: index):
      %38 = "memref.subview"(%14, %arg0) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>, index) -> memref<1x100xf64, strided<[600, 1], offset: ?>>
      %39 = "memref.subview"(%38) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x100xf64, strided<[600, 1], offset: ?>>) -> memref<100xf64, strided<[1], offset: ?>>
      %40 = "memref.subview"(%19) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 100>, static_strides = array<i64: 1, 1>}> : (memref<1x100xf64>) -> memref<100xf64, strided<[1]>>
      %41 = "dma.start_transfer"(%39, %40) : (memref<100xf64, strided<[1], offset: ?>>, memref<100xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%41) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %42 = "memref.subview"(%15, %arg0) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 56, 100>, static_strides = array<i64: 1, 1>}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>, index) -> memref<56x100xf64, strided<[600, 1], offset: ?>>
      %43 = "memref.cast"(%42) : (memref<56x100xf64, strided<[600, 1], offset: ?>>) -> memref<?x100xf64, strided<[600, 1], offset: ?>>
      %44 = "dma.start_transfer"(%43, %24) : (memref<?x100xf64, strided<[600, 1], offset: ?>>, memref<?x100xf64, strided<[100, 1]>>) -> !dma.token
      %45 = "scf.for"(%12, %11, %12, %44) ({
      ^bb0(%arg1: index, %arg2: !dma.token):
        %46 = "affine.min"(%arg1) <{map = affine_map<(d0) -> (161, d0 + 56)>}> : (index) -> index
        %47 = "affine.apply"(%46, %arg1) <{map = affine_map<(d0, d1) -> (d0 - d1)>}> : (index, index) -> index
        %48 = "memref.subview"(%15, %arg1, %arg0, %47) <{operandSegmentSizes = array<i32: 1, 2, 1, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: -9223372036854775808, 100>, static_strides = array<i64: 1, 1>}> : (memref<161x600xf64, strided<[600, 1], offset: 2590800>>, index, index, index) -> memref<?x100xf64, strided<[600, 1], offset: ?>>
        %49 = "affine.apply"(%arg1) <{map = affine_map<(d0) -> ((d0 floordiv 56) mod 2)>}> : (index) -> index
        %50 = "scf.index_switch"(%49) <{cases = array<i64: 0>}> ({
          "scf.yield"(%23) : (memref<56x100xf64>) -> ()
        }, {
          "scf.yield"(%21) : (memref<56x100xf64>) -> ()
        }) : (index) -> memref<56x100xf64>
        %51 = "memref.subview"(%50, %47) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: -9223372036854775808, 100>, static_strides = array<i64: 1, 1>}> : (memref<56x100xf64>, index) -> memref<?x100xf64, strided<[100, 1]>>
        %52 = "dma.start_transfer"(%48, %51) : (memref<?x100xf64, strided<[600, 1], offset: ?>>, memref<?x100xf64, strided<[100, 1]>>) -> !dma.token
        "dma.wait_for_transfer"(%arg2) : (!dma.token) -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "quidditch_snitch.barrier"() : () -> ()
        "scf.yield"(%52) : (!dma.token) -> ()
      }) : (index, index, index, !dma.token) -> !dma.token
      "dma.wait_for_transfer"(%45) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "scf.yield"() : () -> ()
    }) : (index, index, index) -> ()
    %25 = "memref.view"(%13, %1) : (memref<100000xi8>, index) -> memref<168xf64>
    %26 = "memref.reinterpret_cast"(%25) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %27 = "memref.subview"(%26) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x161xf64, strided<[168, 1]>>
    %28 = "memref.subview"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[161, 1], offset: 2687400>>) -> memref<161xf64, strided<[1], offset: 2687400>>
    %29 = "memref.subview"(%27) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[168, 1]>>) -> memref<161xf64, strided<[1]>>
    %30 = "dma.start_transfer"(%28, %29) : (memref<161xf64, strided<[1], offset: 2687400>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%30) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %31 = "memref.view"(%13, %0) : (memref<100000xi8>, index) -> memref<168xf64>
    %32 = "memref.reinterpret_cast"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 168>, static_strides = array<i64: 168, 1>}> : (memref<168xf64>) -> memref<1x168xf64>
    %33 = "memref.subview"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x168xf64>) -> memref<1x161xf64, strided<[168, 1]>>
    %34 = "memref.subview"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64>) -> memref<161xf64, strided<[1]>>
    %35 = "memref.subview"(%33) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 161>, static_strides = array<i64: 1, 1>}> : (memref<1x161xf64, strided<[168, 1]>>) -> memref<161xf64, strided<[1]>>
    %36 = "dma.start_transfer"(%34, %35) : (memref<161xf64, strided<[1]>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%36) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %37 = "dma.start_transfer"(%35, %34) : (memref<161xf64, strided<[1]>>, memref<161xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%37) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
}) : () -> ()
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: note: see current operation: %10 = dma.start_transfer from %subview_16 : memref<1x200xf64, strided<[600, 1], offset: ?>> to %cast : memref<1x200xf64, strided<[200, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %7 = dma.start_transfer from %3 : memref<1x600xf64, strided<[600, 1], offset: 2590200>> to %cast_8 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %9 = dma.start_transfer from %4 : memref<1x600xf64, strided<[600, 1], offset: 600>> to %cast_13 : memref<1x600xf64, strided<[600, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: %11 = dma.start_transfer from %reinterpret_cast_12 : memref<1x600xf64> to %4 : memref<1x600xf64, strided<[600, 1], offset: 600>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: error: failed to legalize operation 'quidditch_snitch.call_microkernel' that was explicitly marked illegal
/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:103:0: note: see current operation: "quidditch_snitch.call_microkernel"(%133, %223, %265) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:\0A    mv t1, a0\0A    mv t0, a1\0A    li t2, 199\0A    scfgwi t2, 64                                # dm 0 dim 0 bound\0A    li t2, -2\0A    scfgwi t2, 96                                # dm 0 dim 1 bound\0A    li t2, 8\0A    scfgwi t2, 192                               # dm 0 dim 0 stride\0A    li t2, -1592\0A    scfgwi t2, 224                               # dm 0 dim 1 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    li t2, -201\0A    scfgwi t2, 65                                # dm 1 dim 0 bound\0A    li t2, 8\0A    scfgwi t2, 193                               # dm 1 dim 0 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t1, 800                               # dm 0 dim 1 source\0A    scfgwi t0, 769                               # dm 1 dim 0 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>) -> ()
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: warning: 
RADDISH (q-convert-to-llvm) applyPartialConversion failed :'(
/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: 
module attributes {llvm.data_layout = "e-m:e-p:32:32-i64:64-n32-S128", llvm.target_triple = "riscv32-unknown-elf"} {
  func.func @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c59200 = arith.constant 59200 : index
    %c54400 = arith.constant 54400 : index
    %c6400 = arith.constant 6400 : index
    %c4800 = arith.constant 4800 : index
    %c0 = arith.constant 0 : index
    %c600 = arith.constant 600 : index
    %c30 = arith.constant 30 : index
    %c200 = arith.constant 200 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %1 = quidditch_snitch.compute_core_index
    %2 = affine.apply affine_map<()[s0] -> (s0 * 75)>()[%1]
    %subview = memref.subview %reinterpret_cast[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0"(%subview) : memref<1x75xf64, strided<[600, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0"
      ".p2align 2"
      "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0:"
      "    mv t0, a0"
      "    fcvt.d.w ft3, zero"
      "    li t1, 74"
      "    scfgwi t1, 64                                # dm 0 dim 0 bound"
      "    li t1, 8"
      "    scfgwi t1, 192                               # dm 0 dim 0 stride"
      "    scfgwi zero, 32                              # dm 0 repeat"
      "    scfgwi t0, 896                               # dm 0 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 74"
      "    frep.o t0, 1, 0, 0"
      "    fmv.d ft0, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c4800][] : memref<100000xi8> to memref<200xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [1, 200], strides: [200, 1] : memref<200xf64> to memref<1x200xf64>
    %view_2 = memref.view %0[%c6400][] : memref<100000xi8> to memref<6000xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [30, 200], strides: [200, 1] : memref<6000xf64> to memref<30x200xf64>
    %3 = affine.apply affine_map<()[s0] -> (s0 * 4)>()[%1]
    scf.for %arg0 = %c0 to %c600 step %c30 {
      scf.for %arg1 = %c0 to %c600 step %c200 {
        quidditch_snitch.barrier
        quidditch_snitch.barrier
        %4 = affine.min affine_map<()[s0] -> (s0 * -4 + 30, 4)>()[%1]
        %subview_10 = memref.subview %reinterpret_cast_3[%3, 0] [%4, 200] [1, 1] : memref<30x200xf64> to memref<?x200xf64, strided<[200, 1], offset: ?>>
        %5 = affine.apply affine_map<()[s0, s1] -> (s0 + s1 * 4)>()[%arg0, %1]
        %subview_11 = memref.subview %reinterpret_cast[0, %5] [1, %4] [1, 1] : memref<1x600xf64> to memref<1x?xf64, strided<[600, 1], offset: ?>>
        quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1"(%reinterpret_cast_1, %subview_10, %subview_11) : memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>[{
          ".text"
          ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1"
          ".p2align 2"
          "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:"
          "    mv t1, a0"
          "    mv t0, a1"
          "    li t2, 199"
          "    scfgwi t2, 64                                # dm 0 dim 0 bound"
          "    li t2, -2"
          "    scfgwi t2, 96                                # dm 0 dim 1 bound"
          "    li t2, 8"
          "    scfgwi t2, 192                               # dm 0 dim 0 stride"
          "    li t2, -1592"
          "    scfgwi t2, 224                               # dm 0 dim 1 stride"
          "    scfgwi zero, 32                              # dm 0 repeat"
          "    li t2, -201"
          "    scfgwi t2, 65                                # dm 1 dim 0 bound"
          "    li t2, 8"
          "    scfgwi t2, 193                               # dm 1 dim 0 stride"
          "    scfgwi zero, 33                              # dm 1 repeat"
          "    scfgwi t1, 800                               # dm 0 dim 1 source"
          "    scfgwi t0, 769                               # dm 1 dim 0 source"
          "    csrrsi zero, 1984, 1                         # SSR enable"
          "    csrrci zero, 1984, 1                         # SSR disable"
          "    ret"
          ""
        }]
        quidditch_snitch.microkernel_fence
        quidditch_snitch.barrier
      }
    }
    %view_4 = memref.view %0[%c54400][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_5 = memref.reinterpret_cast %view_4 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c59200][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_7 = memref.reinterpret_cast %view_6 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    quidditch_snitch.barrier
    %subview_8 = memref.subview %reinterpret_cast_5[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    %subview_9 = memref.subview %reinterpret_cast_7[0, %2] [1, 75] [1, 1] : memref<1x600xf64> to memref<1x75xf64, strided<[600, 1], offset: ?>>
    quidditch_snitch.call_microkernel "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2"(%subview, %subview_8, %subview_9) : memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>[{
      ".text"
      ".globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2"
      ".p2align 2"
      "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2:"
      "    mv t2, a0"
      "    mv t1, a1"
      "    mv t0, a2"
      "    fcvt.d.w ft3, zero"
      "    li t3, 74"
      "    scfgwi t3, 95                                # dm 31 dim 0 bound"
      "    li t3, 8"
      "    scfgwi t3, 223                               # dm 31 dim 0 stride"
      "    scfgwi zero, 63                              # dm 31 repeat"
      "    scfgwi t2, 768                               # dm 0 dim 0 source"
      "    scfgwi t1, 769                               # dm 1 dim 0 source"
      "    scfgwi t0, 898                               # dm 2 dim 0 destination"
      "    csrrsi zero, 1984, 1                         # SSR enable"
      "    li t0, 74"
      "    frep.o t0, 2, 0, 0"
      "    fadd.d ft4, ft0, ft1"
      "    fmax.d ft2, ft4, ft3"
      "    csrrci zero, 1984, 1                         # SSR disable"
      "    ret"
      ""
    }]
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c59200 = arith.constant 59200 : index
    %c54400 = arith.constant 54400 : index
    %c6400 = arith.constant 6400 : index
    %c4800 = arith.constant 4800 : index
    %c20721600 = arith.constant 20721600 : index
    %c17841600 = arith.constant 17841600 : index
    %c0 = arith.constant 0 : index
    %c600 = arith.constant 600 : index
    %c30 = arith.constant 30 : index
    %c200 = arith.constant 200 : index
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x600xf64>
    memref.assume_alignment %1, 64 : memref<1x600xf64>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c17841600) flags(ReadOnly) : memref<600x600xf64, strided<[600, 1], offset: 2230200>>
    memref.assume_alignment %2, 64 : memref<600x600xf64, strided<[600, 1], offset: 2230200>>
    %3 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c20721600) flags(ReadOnly) : memref<1x600xf64, strided<[600, 1], offset: 2590200>>
    memref.assume_alignment %3, 64 : memref<1x600xf64, strided<[600, 1], offset: 2590200>>
    %4 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c4800) : memref<1x600xf64, strided<[600, 1], offset: 600>>
    memref.assume_alignment %4, 64 : memref<1x600xf64, strided<[600, 1], offset: 600>>
    quidditch_snitch.barrier
    %view = memref.view %0[%c4800][] : memref<100000xi8> to memref<200xf64>
    %reinterpret_cast = memref.reinterpret_cast %view to offset: [0], sizes: [1, 200], strides: [200, 1] : memref<200xf64> to memref<1x200xf64>
    %view_0 = memref.view %0[%c6400][] : memref<100000xi8> to memref<6000xf64>
    %reinterpret_cast_1 = memref.reinterpret_cast %view_0 to offset: [0], sizes: [30, 200], strides: [200, 1] : memref<6000xf64> to memref<30x200xf64>
    %cast = memref.cast %reinterpret_cast_1 : memref<30x200xf64> to memref<30x200xf64, strided<[200, 1]>>
    scf.for %arg0 = %c0 to %c600 step %c30 {
      scf.for %arg1 = %c0 to %c600 step %c200 {
        %subview_9 = memref.subview %2[%arg0, %arg1] [30, 200] [1, 1] : memref<600x600xf64, strided<[600, 1], offset: 2230200>> to memref<30x200xf64, strided<[600, 1], offset: ?>>
        %subview_10 = memref.subview %1[0, %arg1] [1, 200] [1, 1] : memref<1x600xf64> to memref<200xf64, strided<[1], offset: ?>>
        %subview_11 = memref.subview %reinterpret_cast[0, 0] [1, 200] [1, 1] : memref<1x200xf64> to memref<200xf64, strided<[1]>>
        %8 = dma.start_transfer from %subview_10 : memref<200xf64, strided<[1], offset: ?>> to %subview_11 : memref<200xf64, strided<[1]>>
        dma.wait_for_transfer %8
        quidditch_snitch.barrier
        %9 = dma.start_transfer from %subview_9 : memref<30x200xf64, strided<[600, 1], offset: ?>> to %cast : memref<30x200xf64, strided<[200, 1]>>
        dma.wait_for_transfer %9
        quidditch_snitch.barrier
        quidditch_snitch.barrier
      }
    }
    %view_2 = memref.view %0[%c54400][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_3 = memref.reinterpret_cast %view_2 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %subview = memref.subview %3[0, 0] [1, 600] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 2590200>> to memref<600xf64, strided<[1], offset: 2590200>>
    %subview_4 = memref.subview %reinterpret_cast_3[0, 0] [1, 600] [1, 1] : memref<1x600xf64> to memref<600xf64, strided<[1]>>
    %5 = dma.start_transfer from %subview : memref<600xf64, strided<[1], offset: 2590200>> to %subview_4 : memref<600xf64, strided<[1]>>
    dma.wait_for_transfer %5
    quidditch_snitch.barrier
    %view_5 = memref.view %0[%c59200][] : memref<100000xi8> to memref<600xf64>
    %reinterpret_cast_6 = memref.reinterpret_cast %view_5 to offset: [0], sizes: [1, 600], strides: [600, 1] : memref<600xf64> to memref<1x600xf64>
    %subview_7 = memref.subview %4[0, 0] [1, 600] [1, 1] : memref<1x600xf64, strided<[600, 1], offset: 600>> to memref<600xf64, strided<[1], offset: 600>>
    %subview_8 = memref.subview %reinterpret_cast_6[0, 0] [1, 600] [1, 1] : memref<1x600xf64> to memref<600xf64, strided<[1]>>
    %6 = dma.start_transfer from %subview_7 : memref<600xf64, strided<[1], offset: 600>> to %subview_8 : memref<600xf64, strided<[1]>>
    dma.wait_for_transfer %6
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %7 = dma.start_transfer from %subview_8 : memref<600xf64, strided<[1]>> to %subview_7 : memref<600xf64, strided<[1], offset: 600>>
    dma.wait_for_transfer %7
    quidditch_snitch.barrier
    return
  }
  llvm.func @snrt_cluster_core_idx() -> i32 attributes {hal.import.bitcode}
  llvm.func @snrt_dma_start_1d(!llvm.ptr, !llvm.ptr, i32) -> i32 attributes {hal.import.bitcode}
  llvm.func @snrt_dma_start_2d(!llvm.ptr, !llvm.ptr, i32, i32, i32, i32) -> i32 attributes {hal.import.bitcode}
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: error: failed to run translation of source executable to target executable for backend #hal.executable.target<"quidditch", "static", {compute_cores = 8 : i32, data_layout = "e-m:e-p:32:32-i64:64-n32-S128", target_triple = "riscv32-unknown-elf"}>
/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:105:0: note: see current operation: 
"hal.executable.variant"() ({
  "hal.executable.export"() ({
  ^bb0(%arg4: !hal.device):
    %65 = "arith.constant"() <{value = 1 : index}> : () -> index
    "hal.return"(%65, %65, %65) : (index, index, index) -> ()
  }) {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>], layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>, ordinal = 0 : index, sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64"} : () -> ()
  "builtin.module"() ({
    "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64"}> ({
      %36 = "arith.constant"() <{value = 59200 : index}> : () -> index
      %37 = "arith.constant"() <{value = 54400 : index}> : () -> index
      %38 = "arith.constant"() <{value = 6400 : index}> : () -> index
      %39 = "arith.constant"() <{value = 4800 : index}> : () -> index
      %40 = "arith.constant"() <{value = 0 : index}> : () -> index
      %41 = "arith.constant"() <{value = 600 : index}> : () -> index
      %42 = "arith.constant"() <{value = 30 : index}> : () -> index
      %43 = "arith.constant"() <{value = 200 : index}> : () -> index
      %44 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
      %45 = "memref.view"(%44, %40) : (memref<100000xi8>, index) -> memref<600xf64>
      %46 = "memref.reinterpret_cast"(%45) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %47 = "quidditch_snitch.compute_core_index"() : () -> index
      %48 = "affine.apply"(%47) <{map = affine_map<()[s0] -> (s0 * 75)>}> : (index) -> index
      %49 = "memref.subview"(%46, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%49) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel0:\0A    mv t0, a0\0A    fcvt.d.w ft3, zero\0A    li t1, 74\0A    scfgwi t1, 64                                # dm 0 dim 0 bound\0A    li t1, 8\0A    scfgwi t1, 192                               # dm 0 dim 0 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    scfgwi t0, 896                               # dm 0 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 74\0A    frep.o t0, 1, 0, 0\0A    fmv.d ft0, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x75xf64, strided<[600, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %50 = "memref.view"(%44, %39) : (memref<100000xi8>, index) -> memref<200xf64>
      %51 = "memref.reinterpret_cast"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 200, 1>}> : (memref<200xf64>) -> memref<1x200xf64>
      %52 = "memref.view"(%44, %38) : (memref<100000xi8>, index) -> memref<6000xf64>
      %53 = "memref.reinterpret_cast"(%52) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 200, 1>}> : (memref<6000xf64>) -> memref<30x200xf64>
      %54 = "affine.apply"(%47) <{map = affine_map<()[s0] -> (s0 * 4)>}> : (index) -> index
      "scf.for"(%40, %41, %42) ({
      ^bb0(%arg2: index):
        "scf.for"(%40, %41, %43) ({
        ^bb0(%arg3: index):
          "quidditch_snitch.barrier"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          %61 = "affine.min"(%47) <{map = affine_map<()[s0] -> (s0 * -4 + 30, 4)>}> : (index) -> index
          %62 = "memref.subview"(%53, %54, %61) <{operandSegmentSizes = array<i32: 1, 1, 1, 0>, static_offsets = array<i64: -9223372036854775808, 0>, static_sizes = array<i64: -9223372036854775808, 200>, static_strides = array<i64: 1, 1>}> : (memref<30x200xf64>, index, index) -> memref<?x200xf64, strided<[200, 1], offset: ?>>
          %63 = "affine.apply"(%arg2, %47) <{map = affine_map<()[s0, s1] -> (s0 + s1 * 4)>}> : (index, index) -> index
          %64 = "memref.subview"(%46, %63, %61) <{operandSegmentSizes = array<i32: 1, 1, 1, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, -9223372036854775808>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index, index) -> memref<1x?xf64, strided<[600, 1], offset: ?>>
          "quidditch_snitch.call_microkernel"(%51, %62, %64) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel1:\0A    mv t1, a0\0A    mv t0, a1\0A    li t2, 199\0A    scfgwi t2, 64                                # dm 0 dim 0 bound\0A    li t2, -2\0A    scfgwi t2, 96                                # dm 0 dim 1 bound\0A    li t2, 8\0A    scfgwi t2, 192                               # dm 0 dim 0 stride\0A    li t2, -1592\0A    scfgwi t2, 224                               # dm 0 dim 1 stride\0A    scfgwi zero, 32                              # dm 0 repeat\0A    li t2, -201\0A    scfgwi t2, 65                                # dm 1 dim 0 bound\0A    li t2, 8\0A    scfgwi t2, 193                               # dm 1 dim 0 stride\0A    scfgwi zero, 33                              # dm 1 repeat\0A    scfgwi t1, 800                               # dm 0 dim 1 source\0A    scfgwi t0, 769                               # dm 1 dim 0 source\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x200xf64>, memref<?x200xf64, strided<[200, 1], offset: ?>>, memref<1x?xf64, strided<[600, 1], offset: ?>>) -> ()
          "quidditch_snitch.microkernel_fence"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "scf.yield"() : () -> ()
        }) : (index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      %55 = "memref.view"(%44, %37) : (memref<100000xi8>, index) -> memref<600xf64>
      %56 = "memref.reinterpret_cast"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %57 = "memref.view"(%44, %36) : (memref<100000xi8>, index) -> memref<600xf64>
      %58 = "memref.reinterpret_cast"(%57) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      "quidditch_snitch.barrier"() : () -> ()
      %59 = "memref.subview"(%56, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      %60 = "memref.subview"(%58, %48) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 75>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<1x75xf64, strided<[600, 1], offset: ?>>
      "quidditch_snitch.call_microkernel"(%49, %59, %60) <{name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2", riscv_assembly = ".text\0A.globl main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2\0A.p2align 2\0Amain$async_dispatch_8_matmul_transpose_b_1x600x600_f64$xdsl_kernel2:\0A    mv t2, a0\0A    mv t1, a1\0A    mv t0, a2\0A    fcvt.d.w ft3, zero\0A    li t3, 74\0A    scfgwi t3, 95                                # dm 31 dim 0 bound\0A    li t3, 8\0A    scfgwi t3, 223                               # dm 31 dim 0 stride\0A    scfgwi zero, 63                              # dm 31 repeat\0A    scfgwi t2, 768                               # dm 0 dim 0 source\0A    scfgwi t1, 769                               # dm 1 dim 0 source\0A    scfgwi t0, 898                               # dm 2 dim 0 destination\0A    csrrsi zero, 1984, 1                         # SSR enable\0A    li t0, 74\0A    frep.o t0, 2, 0, 0\0A    fadd.d ft4, ft0, ft1\0A    fmax.d ft2, ft4, ft3\0A    csrrci zero, 1984, 1                         # SSR disable\0A    ret\0A"}> : (memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>, memref<1x75xf64, strided<[600, 1], offset: ?>>) -> ()
      "quidditch_snitch.microkernel_fence"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "func.return"() : () -> ()
    }) {quidditch_snitch.dma_specialization = @main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
    "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_8_matmul_transpose_b_1x600x600_f64$dma"}> ({
      %0 = "arith.constant"() <{value = 59200 : index}> : () -> index
      %1 = "arith.constant"() <{value = 54400 : index}> : () -> index
      %2 = "arith.constant"() <{value = 6400 : index}> : () -> index
      %3 = "arith.constant"() <{value = 4800 : index}> : () -> index
      %4 = "arith.constant"() <{value = 20721600 : index}> : () -> index
      %5 = "arith.constant"() <{value = 17841600 : index}> : () -> index
      %6 = "arith.constant"() <{value = 0 : index}> : () -> index
      %7 = "arith.constant"() <{value = 600 : index}> : () -> index
      %8 = "arith.constant"() <{value = 30 : index}> : () -> index
      %9 = "arith.constant"() <{value = 200 : index}> : () -> index
      %10 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
      %11 = "hal.interface.binding.subspan"(%6) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64>
      "memref.assume_alignment"(%11) <{alignment = 64 : i32}> : (memref<1x600xf64>) -> ()
      %12 = "hal.interface.binding.subspan"(%5) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<600x600xf64, strided<[600, 1], offset: 2230200>>
      "memref.assume_alignment"(%12) <{alignment = 64 : i32}> : (memref<600x600xf64, strided<[600, 1], offset: 2230200>>) -> ()
      %13 = "hal.interface.binding.subspan"(%4) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 2590200>>
      "memref.assume_alignment"(%13) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 2590200>>) -> ()
      %14 = "hal.interface.binding.subspan"(%3) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<1x600xf64, strided<[600, 1], offset: 600>>
      "memref.assume_alignment"(%14) <{alignment = 64 : i32}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %15 = "memref.view"(%10, %3) : (memref<100000xi8>, index) -> memref<200xf64>
      %16 = "memref.reinterpret_cast"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 200, 1>}> : (memref<200xf64>) -> memref<1x200xf64>
      %17 = "memref.view"(%10, %2) : (memref<100000xi8>, index) -> memref<6000xf64>
      %18 = "memref.reinterpret_cast"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 200, 1>}> : (memref<6000xf64>) -> memref<30x200xf64>
      %19 = "memref.cast"(%18) : (memref<30x200xf64>) -> memref<30x200xf64, strided<[200, 1]>>
      "scf.for"(%6, %7, %8) ({
      ^bb0(%arg0: index):
        "scf.for"(%6, %7, %9) ({
        ^bb0(%arg1: index):
          %31 = "memref.subview"(%12, %arg0, %arg1) <{operandSegmentSizes = array<i32: 1, 2, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 30, 200>, static_strides = array<i64: 1, 1>}> : (memref<600x600xf64, strided<[600, 1], offset: 2230200>>, index, index) -> memref<30x200xf64, strided<[600, 1], offset: ?>>
          %32 = "memref.subview"(%11, %arg1) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>, index) -> memref<200xf64, strided<[1], offset: ?>>
          %33 = "memref.subview"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 200>, static_strides = array<i64: 1, 1>}> : (memref<1x200xf64>) -> memref<200xf64, strided<[1]>>
          %34 = "dma.start_transfer"(%32, %33) : (memref<200xf64, strided<[1], offset: ?>>, memref<200xf64, strided<[1]>>) -> !dma.token
          "dma.wait_for_transfer"(%34) : (!dma.token) -> ()
          "quidditch_snitch.barrier"() : () -> ()
          %35 = "dma.start_transfer"(%31, %19) : (memref<30x200xf64, strided<[600, 1], offset: ?>>, memref<30x200xf64, strided<[200, 1]>>) -> !dma.token
          "dma.wait_for_transfer"(%35) : (!dma.token) -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "quidditch_snitch.barrier"() : () -> ()
          "scf.yield"() : () -> ()
        }) : (index, index, index) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      %20 = "memref.view"(%10, %1) : (memref<100000xi8>, index) -> memref<600xf64>
      %21 = "memref.reinterpret_cast"(%20) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %22 = "memref.subview"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 2590200>>) -> memref<600xf64, strided<[1], offset: 2590200>>
      %23 = "memref.subview"(%21) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>) -> memref<600xf64, strided<[1]>>
      %24 = "dma.start_transfer"(%22, %23) : (memref<600xf64, strided<[1], offset: 2590200>>, memref<600xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%24) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %25 = "memref.view"(%10, %0) : (memref<100000xi8>, index) -> memref<600xf64>
      %26 = "memref.reinterpret_cast"(%25) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 600, 1>}> : (memref<600xf64>) -> memref<1x600xf64>
      %27 = "memref.subview"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64, strided<[600, 1], offset: 600>>) -> memref<600xf64, strided<[1], offset: 600>>
      %28 = "memref.subview"(%26) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0>, static_sizes = array<i64: 1, 600>, static_strides = array<i64: 1, 1>}> : (memref<1x600xf64>) -> memref<600xf64, strided<[1]>>
      %29 = "dma.start_transfer"(%27, %28) : (memref<600xf64, strided<[1], offset: 600>>, memref<600xf64, strided<[1]>>) -> !dma.token
      "dma.wait_for_transfer"(%29) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "quidditch_snitch.barrier"() : () -> ()
      %30 = "dma.start_transfer"(%28, %27) : (memref<600xf64, strided<[1]>>, memref<600xf64, strided<[1], offset: 600>>) -> !dma.token
      "dma.wait_for_transfer"(%30) : (!dma.token) -> ()
      "quidditch_snitch.barrier"() : () -> ()
      "func.return"() : () -> ()
    }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 ()>, linkage = #llvm.linkage<external>, sym_name = "snrt_cluster_core_idx", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 (ptr, ptr, i32)>, linkage = #llvm.linkage<external>, sym_name = "snrt_dma_start_1d", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
    "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<i32 (ptr, ptr, i32, i32, i32, i32)>, linkage = #llvm.linkage<external>, sym_name = "snrt_dma_start_2d", visibility_ = 0 : i64}> ({
    }) {hal.import.bitcode} : () -> ()
  }) {llvm.data_layout = "e-m:e-p:32:32-i64:64-n32-S128", llvm.target_triple = "riscv32-unknown-elf"} : () -> ()
  "hal.executable.variant_end"() : () -> ()
}) {sym_name = "static", target = #hal.executable.target<"quidditch", "static", {compute_cores = 8 : i32, data_layout = "e-m:e-p:32:32-i64:64-n32-S128", target_triple = "riscv32-unknown-elf"}>} : () -> ()
failed to translate executables
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: Failed to translate kernel with xDSL
/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
quidditch_snitch.memref.microkernel(<<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>, <<UNKNOWN SSA VALUE>>) : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>> {
^bb0(%arg0: memref<50xf64, strided<[1], offset: ?>>, %arg1: memref<50xf64, strided<[1], offset: ?>>, %arg2: memref<50xf64, strided<[1], offset: ?>>, %arg3: memref<50xf64, strided<[1], offset: ?>>, %arg4: memref<50xf64, strided<[1], offset: ?>>, %arg5: memref<50xf64, strided<[1], offset: ?>>, %arg6: memref<50xf64, strided<[1], offset: ?>>, %arg7: memref<50xf64, strided<[1], offset: ?>>):
  %cst = arith.constant 1.000000e+00 : f64
  linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6 : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) outs(%arg7 : memref<50xf64, strided<[1], offset: ?>>) {
  ^bb0(%in: f64, %in_0: f64, %in_1: f64, %in_2: f64, %in_3: f64, %in_4: f64, %in_5: f64, %out: f64):
    %0 = arith.addf %in_4, %in_5 : f64
    %1 = arith.addf %in_2, %in_3 : f64
    %2 = arith.negf %1 : f64
    %3 = math.exp %2 : f64
    %4 = arith.addf %3, %cst : f64
    %5 = arith.divf %cst, %4 : f64
    %6 = arith.mulf %in_1, %5 : f64
    %7 = arith.addf %in_0, %6 : f64
    %8 = math.tanh %7 : f64
    %9 = arith.negf %0 : f64
    %10 = math.exp %9 : f64
    %11 = arith.addf %10, %cst : f64
    %12 = arith.divf %cst, %11 : f64
    %13 = arith.subf %in, %8 : f64
    %14 = arith.mulf %13, %12 : f64
    %15 = arith.addf %14, %8 : f64
    linalg.yield %15 : f64
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: stderr:
Traceback (most recent call last):
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 534, in parse_chunk
    return self.available_frontends[file_extension](chunk)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 520, in parse_mlir
    ).parse_module(not self.args.no_implicit_module)
      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 127, in parse_module
    if (parsed_op := self.parse_optional_operation()) is not None:
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/func.py", line 138, in parse
    ) = parse_func_op_like(
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/utils.py", line 239, in parse_func_op_like
    region = parser.parse_optional_region(entry_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 539, in parse_optional_region
    self._parse_block_body(entry_block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/dialects/linalg.py", line 354, in parse
    body = parser.parse_region()
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 594, in parse_region
    region = self.parse_optional_region(arguments)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 558, in parse_optional_region
    block = self._parse_block()
            ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 247, in _parse_block
    self._parse_block_body(block)
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 217, in _parse_block_body
    while (op := self.parse_optional_operation()) is not None:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 675, in parse_optional_operation
    return self.parse_operation()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/core.py", line 702, in parse_operation
    op = op_type.parse(self)
         ^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/ir/core.py", line 869, in parse
    parser.raise_error(f"Operation {cls.name} does not have a custom format.")
  File "/home/hoppip/Quidditch/xdsl/xdsl/parser/base_parser.py", line 107, in raise_error
    raise ParseError(at_position, msg)
xdsl.utils.exceptions.ParseError: stdin:8:18
    %3 = math.exp %2 : f64
                  ^^
                  Operation math.exp does not have a custom format.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hoppip/Quidditch/venv/bin/xdsl-opt", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/xdsl_opt.py", line 5, in main
    xDSLOptMain().run()
  File "/home/hoppip/Quidditch/xdsl/xdsl/xdsl_opt_main.py", line 71, in run
    module = self.parse_chunk(chunk, file_extension, offset)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoppip/Quidditch/xdsl/xdsl/tools/command_line_tool.py", line 541, in parse_chunk
    raise Exception("Failed to parse:\n" + e.with_context()) from e
Exception: Failed to parse:
stdin:8:18
    %3 = math.exp %2 : f64
                  ^^
                  Operation math.exp does not have a custom format.


<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: 
RADDISH: (convertToRISCV) convert to RISCV assembly failed

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
module {
  func.func @main$async_dispatch_3_elementwise_400_f64() attributes {quidditch_snitch.dma_specialization = @main$async_dispatch_3_elementwise_400_f64$dma, translation_info = #iree_codegen.translation_info<None>} {
    %c22400 = arith.constant 22400 : index
    %c19200 = arith.constant 19200 : index
    %c16000 = arith.constant 16000 : index
    %c12800 = arith.constant 12800 : index
    %c9600 = arith.constant 9600 : index
    %c6400 = arith.constant 6400 : index
    %c3200 = arith.constant 3200 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.constant.load[0] : i32
    %2 = hal.interface.constant.load[1] : i32
    %3 = hal.interface.constant.load[2] : i32
    %4 = hal.interface.constant.load[3] : i32
    %5 = hal.interface.constant.load[4] : i32
    %6 = hal.interface.constant.load[5] : i32
    %7 = hal.interface.constant.load[6] : i32
    %8 = hal.interface.constant.load[7] : i32
    %9 = hal.interface.constant.load[8] : i32
    %10 = arith.extui %1 : i32 to i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.ori %10, %12 : i64
    %14 = arith.index_castui %13 {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : i64 to index
    %15 = arith.index_castui %3 : i32 to index
    %16 = arith.index_castui %4 : i32 to index
    %17 = arith.index_castui %5 : i32 to index
    %18 = arith.index_castui %6 : i32 to index
    %19 = arith.index_castui %7 : i32 to index
    %20 = arith.index_castui %8 : i32 to index
    %21 = arith.index_castui %9 : i32 to index
    %22 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%14) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %22, 64 : memref<400xf64, strided<[1], offset: ?>>
    %23 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%15) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %23, 1 : memref<400xf64, strided<[1], offset: ?>>
    %24 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%16) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %24, 1 : memref<400xf64, strided<[1], offset: ?>>
    %25 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%17) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %25, 1 : memref<400xf64, strided<[1], offset: ?>>
    %26 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%18) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %26, 1 : memref<400xf64, strided<[1], offset: ?>>
    %27 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%19) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %27, 1 : memref<400xf64, strided<[1], offset: ?>>
    %28 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%20) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %28, 1 : memref<400xf64, strided<[1], offset: ?>>
    %29 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%21) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %29, 1 : memref<400xf64, strided<[1], offset: ?>>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c3200][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_1 = memref.view %0[%c6400][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_2 = memref.view %0[%c9600][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_3 = memref.view %0[%c12800][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_4 = memref.view %0[%c16000][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_5 = memref.view %0[%c19200][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c22400][] : memref<100000xi8> to memref<400xf64>
    quidditch_snitch.barrier
    %30 = quidditch_snitch.compute_core_index
    %31 = affine.apply affine_map<()[s0] -> (s0 * 50)>()[%30]
    %subview = memref.subview %view[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_7 = memref.subview %view_0[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_8 = memref.subview %view_1[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_9 = memref.subview %view_2[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_10 = memref.subview %view_3[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_11 = memref.subview %view_4[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_12 = memref.subview %view_5[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    %subview_13 = memref.subview %view_6[%31] [50] [1] : memref<400xf64> to memref<50xf64, strided<[1], offset: ?>>
    quidditch_snitch.memref.microkernel(%subview, %subview_7, %subview_8, %subview_9, %subview_10, %subview_11, %subview_12, %subview_13) : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>> {
    ^bb0(%arg0: memref<50xf64, strided<[1], offset: ?>>, %arg1: memref<50xf64, strided<[1], offset: ?>>, %arg2: memref<50xf64, strided<[1], offset: ?>>, %arg3: memref<50xf64, strided<[1], offset: ?>>, %arg4: memref<50xf64, strided<[1], offset: ?>>, %arg5: memref<50xf64, strided<[1], offset: ?>>, %arg6: memref<50xf64, strided<[1], offset: ?>>, %arg7: memref<50xf64, strided<[1], offset: ?>>):
      %cst = arith.constant 1.000000e+00 : f64
      linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6 : memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) outs(%arg7 : memref<50xf64, strided<[1], offset: ?>>) {
      ^bb0(%in: f64, %in_14: f64, %in_15: f64, %in_16: f64, %in_17: f64, %in_18: f64, %in_19: f64, %out: f64):
        %32 = arith.addf %in_18, %in_19 : f64
        %33 = arith.addf %in_16, %in_17 : f64
        %34 = arith.negf %33 : f64
        %35 = math.exp %34 : f64
        %36 = arith.addf %35, %cst : f64
        %37 = arith.divf %cst, %36 : f64
        %38 = arith.mulf %in_15, %37 : f64
        %39 = arith.addf %in_14, %38 : f64
        %40 = math.tanh %39 : f64
        %41 = arith.negf %32 : f64
        %42 = math.exp %41 : f64
        %43 = arith.addf %42, %cst : f64
        %44 = arith.divf %cst, %43 : f64
        %45 = arith.subf %in, %40 : f64
        %46 = arith.mulf %45, %44 : f64
        %47 = arith.addf %46, %40 : f64
        linalg.yield %47 : f64
      }
    }
    quidditch_snitch.microkernel_fence
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    return
  }
  func.func @main$async_dispatch_3_elementwise_400_f64$dma() attributes {translation_info = #iree_codegen.translation_info<None>} {
    %c22400 = arith.constant 22400 : index
    %c19200 = arith.constant 19200 : index
    %c16000 = arith.constant 16000 : index
    %c12800 = arith.constant 12800 : index
    %c9600 = arith.constant 9600 : index
    %c6400 = arith.constant 6400 : index
    %c3200 = arith.constant 3200 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = quidditch_snitch.l1_memory_view -> memref<100000xi8>
    %1 = hal.interface.constant.load[0] : i32
    %2 = hal.interface.constant.load[1] : i32
    %3 = hal.interface.constant.load[2] : i32
    %4 = hal.interface.constant.load[3] : i32
    %5 = hal.interface.constant.load[4] : i32
    %6 = hal.interface.constant.load[5] : i32
    %7 = hal.interface.constant.load[6] : i32
    %8 = hal.interface.constant.load[7] : i32
    %9 = hal.interface.constant.load[8] : i32
    %10 = arith.extui %1 : i32 to i64
    %11 = arith.extui %2 : i32 to i64
    %12 = arith.shli %11, %c32_i64 : i64
    %13 = arith.ori %10, %12 : i64
    %14 = arith.index_castui %13 {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : i64 to index
    %15 = arith.index_castui %3 : i32 to index
    %16 = arith.index_castui %4 : i32 to index
    %17 = arith.index_castui %5 : i32 to index
    %18 = arith.index_castui %6 : i32 to index
    %19 = arith.index_castui %7 : i32 to index
    %20 = arith.index_castui %8 : i32 to index
    %21 = arith.index_castui %9 : i32 to index
    %22 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%14) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %22, 64 : memref<400xf64, strided<[1], offset: ?>>
    %23 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%15) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %23, 1 : memref<400xf64, strided<[1], offset: ?>>
    %24 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%16) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %24, 1 : memref<400xf64, strided<[1], offset: ?>>
    %25 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%17) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %25, 1 : memref<400xf64, strided<[1], offset: ?>>
    %26 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%18) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %26, 1 : memref<400xf64, strided<[1], offset: ?>>
    %27 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%19) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %27, 1 : memref<400xf64, strided<[1], offset: ?>>
    %28 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%20) flags(ReadOnly) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %28, 1 : memref<400xf64, strided<[1], offset: ?>>
    %29 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%21) : memref<400xf64, strided<[1], offset: ?>>
    memref.assume_alignment %29, 1 : memref<400xf64, strided<[1], offset: ?>>
    %view = memref.view %0[%c0][] : memref<100000xi8> to memref<400xf64>
    %cast = memref.cast %view : memref<400xf64> to memref<400xf64, strided<[1]>>
    %30 = dma.start_transfer from %22 : memref<400xf64, strided<[1], offset: ?>> to %cast : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %30
    quidditch_snitch.barrier
    %view_0 = memref.view %0[%c3200][] : memref<100000xi8> to memref<400xf64>
    %cast_1 = memref.cast %view_0 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %31 = dma.start_transfer from %23 : memref<400xf64, strided<[1], offset: ?>> to %cast_1 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %31
    quidditch_snitch.barrier
    %view_2 = memref.view %0[%c6400][] : memref<100000xi8> to memref<400xf64>
    %cast_3 = memref.cast %view_2 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %32 = dma.start_transfer from %24 : memref<400xf64, strided<[1], offset: ?>> to %cast_3 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %32
    quidditch_snitch.barrier
    %view_4 = memref.view %0[%c9600][] : memref<100000xi8> to memref<400xf64>
    %cast_5 = memref.cast %view_4 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %33 = dma.start_transfer from %25 : memref<400xf64, strided<[1], offset: ?>> to %cast_5 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %33
    quidditch_snitch.barrier
    %view_6 = memref.view %0[%c12800][] : memref<100000xi8> to memref<400xf64>
    %cast_7 = memref.cast %view_6 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %34 = dma.start_transfer from %26 : memref<400xf64, strided<[1], offset: ?>> to %cast_7 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %34
    quidditch_snitch.barrier
    %view_8 = memref.view %0[%c16000][] : memref<100000xi8> to memref<400xf64>
    %cast_9 = memref.cast %view_8 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %35 = dma.start_transfer from %27 : memref<400xf64, strided<[1], offset: ?>> to %cast_9 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %35
    quidditch_snitch.barrier
    %view_10 = memref.view %0[%c19200][] : memref<100000xi8> to memref<400xf64>
    %cast_11 = memref.cast %view_10 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %36 = dma.start_transfer from %28 : memref<400xf64, strided<[1], offset: ?>> to %cast_11 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %36
    quidditch_snitch.barrier
    %view_12 = memref.view %0[%c22400][] : memref<100000xi8> to memref<400xf64>
    %cast_13 = memref.cast %view_12 : memref<400xf64> to memref<400xf64, strided<[1]>>
    %37 = dma.start_transfer from %29 : memref<400xf64, strided<[1], offset: ?>> to %cast_13 : memref<400xf64, strided<[1]>>
    dma.wait_for_transfer %37
    quidditch_snitch.barrier
    quidditch_snitch.barrier
    %38 = dma.start_transfer from %view_12 : memref<400xf64> to %29 : memref<400xf64, strided<[1], offset: ?>>
    dma.wait_for_transfer %38
    quidditch_snitch.barrier
    return
  }
}
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: warning: 
RADDISH: (convertToRISCV) erasing the kernel op and continuing on...

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:47:0: note: see current operation: 
"builtin.module"() ({
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_3_elementwise_400_f64"}> ({
    %64 = "arith.constant"() <{value = 22400 : index}> : () -> index
    %65 = "arith.constant"() <{value = 19200 : index}> : () -> index
    %66 = "arith.constant"() <{value = 16000 : index}> : () -> index
    %67 = "arith.constant"() <{value = 12800 : index}> : () -> index
    %68 = "arith.constant"() <{value = 9600 : index}> : () -> index
    %69 = "arith.constant"() <{value = 6400 : index}> : () -> index
    %70 = "arith.constant"() <{value = 3200 : index}> : () -> index
    %71 = "arith.constant"() <{value = 0 : index}> : () -> index
    %72 = "arith.constant"() <{value = 32 : i64}> : () -> i64
    %73 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %74 = "hal.interface.constant.load"() {index = 0 : index} : () -> i32
    %75 = "hal.interface.constant.load"() {index = 1 : index} : () -> i32
    %76 = "hal.interface.constant.load"() {index = 2 : index} : () -> i32
    %77 = "hal.interface.constant.load"() {index = 3 : index} : () -> i32
    %78 = "hal.interface.constant.load"() {index = 4 : index} : () -> i32
    %79 = "hal.interface.constant.load"() {index = 5 : index} : () -> i32
    %80 = "hal.interface.constant.load"() {index = 6 : index} : () -> i32
    %81 = "hal.interface.constant.load"() {index = 7 : index} : () -> i32
    %82 = "hal.interface.constant.load"() {index = 8 : index} : () -> i32
    %83 = "arith.extui"(%74) : (i32) -> i64
    %84 = "arith.extui"(%75) : (i32) -> i64
    %85 = "arith.shli"(%84, %72) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %86 = "arith.ori"(%83, %85) : (i64, i64) -> i64
    %87 = "arith.index_castui"(%86) {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : (i64) -> index
    %88 = "arith.index_castui"(%76) : (i32) -> index
    %89 = "arith.index_castui"(%77) : (i32) -> index
    %90 = "arith.index_castui"(%78) : (i32) -> index
    %91 = "arith.index_castui"(%79) : (i32) -> index
    %92 = "arith.index_castui"(%80) : (i32) -> index
    %93 = "arith.index_castui"(%81) : (i32) -> index
    %94 = "arith.index_castui"(%82) : (i32) -> index
    %95 = "hal.interface.binding.subspan"(%87) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%95) <{alignment = 64 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %96 = "hal.interface.binding.subspan"(%88) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%96) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %97 = "hal.interface.binding.subspan"(%89) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%97) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %98 = "hal.interface.binding.subspan"(%90) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%98) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %99 = "hal.interface.binding.subspan"(%91) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%99) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %100 = "hal.interface.binding.subspan"(%92) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%100) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %101 = "hal.interface.binding.subspan"(%93) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%101) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %102 = "hal.interface.binding.subspan"(%94) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%102) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %103 = "memref.view"(%73, %71) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %104 = "memref.view"(%73, %70) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %105 = "memref.view"(%73, %69) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %106 = "memref.view"(%73, %68) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %107 = "memref.view"(%73, %67) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %108 = "memref.view"(%73, %66) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %109 = "memref.view"(%73, %65) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %110 = "memref.view"(%73, %64) : (memref<100000xi8>, index) -> memref<400xf64>
    "quidditch_snitch.barrier"() : () -> ()
    %111 = "quidditch_snitch.compute_core_index"() : () -> index
    %112 = "affine.apply"(%111) <{map = affine_map<()[s0] -> (s0 * 50)>}> : (index) -> index
    %113 = "memref.subview"(%103, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %114 = "memref.subview"(%104, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %115 = "memref.subview"(%105, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %116 = "memref.subview"(%106, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %117 = "memref.subview"(%107, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %118 = "memref.subview"(%108, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %119 = "memref.subview"(%109, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %120 = "memref.subview"(%110, %112) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 50>, static_strides = array<i64: 1>}> : (memref<400xf64>, index) -> memref<50xf64, strided<[1], offset: ?>>
    %121 = "arith.constant"() <{value = 1.000000e+00 : f64}> : () -> f64
    "linalg.generic"(%113, %114, %115, %116, %117, %118, %119, %120) <{indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = [#linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 7, 1>}> ({
    ^bb0(%arg0: f64, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64, %arg5: f64, %arg6: f64, %arg7: f64):
      %122 = "arith.addf"(%arg5, %arg6) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %123 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %124 = "arith.negf"(%123) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %125 = "math.exp"(%124) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %126 = "arith.addf"(%125, %121) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %127 = "arith.divf"(%121, %126) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %128 = "arith.mulf"(%arg2, %127) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %129 = "arith.addf"(%arg1, %128) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %130 = "math.tanh"(%129) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %131 = "arith.negf"(%122) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %132 = "math.exp"(%131) <{fastmath = #arith.fastmath<none>}> : (f64) -> f64
      %133 = "arith.addf"(%132, %121) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %134 = "arith.divf"(%121, %133) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %135 = "arith.subf"(%arg0, %130) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %136 = "arith.mulf"(%135, %134) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      %137 = "arith.addf"(%136, %130) <{fastmath = #arith.fastmath<none>}> : (f64, f64) -> f64
      "linalg.yield"(%137) : (f64) -> ()
    }) : (memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) -> ()
    "quidditch_snitch.memref.microkernel"(%113, %114, %115, %116, %117, %118, %119, %120) ({
    }) : (memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>, memref<50xf64, strided<[1], offset: ?>>) -> ()
    "quidditch_snitch.microkernel_fence"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {quidditch_snitch.dma_specialization = @main$async_dispatch_3_elementwise_400_f64$dma, translation_info = #iree_codegen.translation_info<None>} : () -> ()
  "func.func"() <{function_type = () -> (), sym_name = "main$async_dispatch_3_elementwise_400_f64$dma"}> ({
    %0 = "arith.constant"() <{value = 22400 : index}> : () -> index
    %1 = "arith.constant"() <{value = 19200 : index}> : () -> index
    %2 = "arith.constant"() <{value = 16000 : index}> : () -> index
    %3 = "arith.constant"() <{value = 12800 : index}> : () -> index
    %4 = "arith.constant"() <{value = 9600 : index}> : () -> index
    %5 = "arith.constant"() <{value = 6400 : index}> : () -> index
    %6 = "arith.constant"() <{value = 3200 : index}> : () -> index
    %7 = "arith.constant"() <{value = 0 : index}> : () -> index
    %8 = "arith.constant"() <{value = 32 : i64}> : () -> i64
    %9 = "quidditch_snitch.l1_memory_view"() : () -> memref<100000xi8>
    %10 = "hal.interface.constant.load"() {index = 0 : index} : () -> i32
    %11 = "hal.interface.constant.load"() {index = 1 : index} : () -> i32
    %12 = "hal.interface.constant.load"() {index = 2 : index} : () -> i32
    %13 = "hal.interface.constant.load"() {index = 3 : index} : () -> i32
    %14 = "hal.interface.constant.load"() {index = 4 : index} : () -> i32
    %15 = "hal.interface.constant.load"() {index = 5 : index} : () -> i32
    %16 = "hal.interface.constant.load"() {index = 6 : index} : () -> i32
    %17 = "hal.interface.constant.load"() {index = 7 : index} : () -> i32
    %18 = "hal.interface.constant.load"() {index = 8 : index} : () -> i32
    %19 = "arith.extui"(%10) : (i32) -> i64
    %20 = "arith.extui"(%11) : (i32) -> i64
    %21 = "arith.shli"(%20, %8) <{overflowFlags = #arith.overflow<none>}> : (i64, i64) -> i64
    %22 = "arith.ori"(%19, %21) : (i64, i64) -> i64
    %23 = "arith.index_castui"(%22) {stream.alignment = 128 : index, stream.values = [0 : index, 3200 : index]} : (i64) -> index
    %24 = "arith.index_castui"(%12) : (i32) -> index
    %25 = "arith.index_castui"(%13) : (i32) -> index
    %26 = "arith.index_castui"(%14) : (i32) -> index
    %27 = "arith.index_castui"(%15) : (i32) -> index
    %28 = "arith.index_castui"(%16) : (i32) -> index
    %29 = "arith.index_castui"(%17) : (i32) -> index
    %30 = "arith.index_castui"(%18) : (i32) -> index
    %31 = "hal.interface.binding.subspan"(%23) {alignment = 64 : index, binding = 0 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%31) <{alignment = 64 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %32 = "hal.interface.binding.subspan"(%24) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%32) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %33 = "hal.interface.binding.subspan"(%25) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%33) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %34 = "hal.interface.binding.subspan"(%26) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%34) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %35 = "hal.interface.binding.subspan"(%27) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%35) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %36 = "hal.interface.binding.subspan"(%28) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%36) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %37 = "hal.interface.binding.subspan"(%29) {alignment = 64 : index, binding = 1 : index, descriptor_flags = 1 : i32, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%37) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %38 = "hal.interface.binding.subspan"(%30) {alignment = 64 : index, binding = 2 : index, descriptor_type = #hal.descriptor_type<storage_buffer>, operandSegmentSizes = array<i32: 1, 0>, set = 0 : index} : (index) -> memref<400xf64, strided<[1], offset: ?>>
    "memref.assume_alignment"(%38) <{alignment = 1 : i32}> : (memref<400xf64, strided<[1], offset: ?>>) -> ()
    %39 = "memref.view"(%9, %7) : (memref<100000xi8>, index) -> memref<400xf64>
    %40 = "memref.cast"(%39) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %41 = "dma.start_transfer"(%31, %40) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%41) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %42 = "memref.view"(%9, %6) : (memref<100000xi8>, index) -> memref<400xf64>
    %43 = "memref.cast"(%42) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %44 = "dma.start_transfer"(%32, %43) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%44) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %45 = "memref.view"(%9, %5) : (memref<100000xi8>, index) -> memref<400xf64>
    %46 = "memref.cast"(%45) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %47 = "dma.start_transfer"(%33, %46) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%47) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %48 = "memref.view"(%9, %4) : (memref<100000xi8>, index) -> memref<400xf64>
    %49 = "memref.cast"(%48) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %50 = "dma.start_transfer"(%34, %49) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%50) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %51 = "memref.view"(%9, %3) : (memref<100000xi8>, index) -> memref<400xf64>
    %52 = "memref.cast"(%51) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %53 = "dma.start_transfer"(%35, %52) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%53) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %54 = "memref.view"(%9, %2) : (memref<100000xi8>, index) -> memref<400xf64>
    %55 = "memref.cast"(%54) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %56 = "dma.start_transfer"(%36, %55) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%56) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %57 = "memref.view"(%9, %1) : (memref<100000xi8>, index) -> memref<400xf64>
    %58 = "memref.cast"(%57) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %59 = "dma.start_transfer"(%37, %58) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%59) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %60 = "memref.view"(%9, %0) : (memref<100000xi8>, index) -> memref<400xf64>
    %61 = "memref.cast"(%60) : (memref<400xf64>) -> memref<400xf64, strided<[1]>>
    %62 = "dma.start_transfer"(%38, %61) : (memref<400xf64, strided<[1], offset: ?>>, memref<400xf64, strided<[1]>>) -> !dma.token
    "dma.wait_for_transfer"(%62) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "quidditch_snitch.barrier"() : () -> ()
    %63 = "dma.start_transfer"(%60, %38) : (memref<400xf64>, memref<400xf64, strided<[1], offset: ?>>) -> !dma.token
    "dma.wait_for_transfer"(%63) : (!dma.token) -> ()
    "quidditch_snitch.barrier"() : () -> ()
    "func.return"() : () -> ()
  }) {translation_info = #iree_codegen.translation_info<None>} : () -> ()
}) : () -> ()
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %6 = dma.start_transfer from %1 : memref<1x161xf64> to %cast : memref<1x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %12 = dma.start_transfer from %subview_17 : memref<40x161xf64, strided<[161, 1], offset: ?>> to %cast_7 : memref<40x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: RADDISH PROBLEM: type.getShape().front() = 40 is NOT 1

RADDISH: (legalize DMA operations) failed to remove outer unit dimensions

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %12 = dma.start_transfer from %subview_17 : memref<40x161xf64, strided<[161, 1], offset: ?>> to %cast_7 : memref<40x161xf64, strided<[161, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %9 = dma.start_transfer from %3 : memref<1x400xf64, strided<[400, 1], offset: 64400>> to %cast_10 : memref<1x400xf64, strided<[400, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %11 = dma.start_transfer from %4 : memref<1x400xf64> to %cast_15 : memref<1x400xf64, strided<[400, 1]>>
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: warning: 
RADDISH: (legalize DMA operations) failed to add contiguous inner unit somehow :(

/home/hoppip/Quidditch/runtime/samples/nsnet2/NsNet2.py:90:0: note: called from
<eval_with_key>.0 from /home/hoppip/Quidditch/venv/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:551 in wrapped:10:0: note: see current operation: %13 = dma.start_transfer from %reinterpret_cast_14 : memref<1x400xf64> to %4 : memref<1x400xf64>
ninja: build stopped: subcommand failed.
FAILED: runtime-prefix/src/runtime-stamp/runtime-build /home/hoppip/Quidditch/build/runtime-prefix/src/runtime-stamp/runtime-build 
cd /home/hoppip/Quidditch/build/runtime && /usr/bin/cmake --build .
ninja: build stopped: subcommand failed.
